from abc import ABC, abstractmethod
import os
from typing import Dict, List, Union
import warnings

import mariadb
import pandas as pd
import xml.etree.ElementTree as ET

import file_handling
from file_handling import FileHandler
from vehicle import VehicleType, vehicle_type_to_str_map


def match_sim_number_to_random_seed(data):
    """Matches each simulation number to the used random seed. This is only
    possible if we know the initial random seed, the random seed increment,
    and the number of runs per vehicle input."""
    # TODO: where should this function and these constants be saved?
    # These variables are needed because we only save the simulation number,
    # which doesn't mean much unless all percentages had the
    # exact same number of simulations.
    _first_simulation_number = 1  # TODO: depends on the scenario
    _runs_per_input = 10
    _initial_random_seed = 7
    _random_seed_increment = 1
    if not data.empty:
        data['random_seed'] = _initial_random_seed + (
                (data['simulation_number'] - _first_simulation_number)
                % _runs_per_input) * _random_seed_increment


def _add_vehicle_type_columns(data: pd.DataFrame,
                              vehicle_percentages: Dict[VehicleType, int]):
                              # vehicle_type: List[VehicleType],
                              # controlled_vehicles_percentage: List[int]):
    if vehicle_percentages is not None:
        s = ''
        if sum(vehicle_percentages.values()) == 0:
            s = 'no control'
        for vt, p in vehicle_percentages.items():
            data[vt.name.lower() + '_percentage'] = p
            if p > 0:
                s += str(p) + '% ' + vehicle_type_to_str_map[vt]
        data['control percentages'] = s
        # for i in range(len(vehicle_type)):
        #     data[vehicle_type[i].name.lower() + '_percentage'] = (
        #         controlled_vehicles_percentage[i])
        #     if controlled_vehicles_percentage[i] > 0:
        #         s += (str(controlled_vehicles_percentage[i]) + '% '
        #               + vehicle_type_to_str_map[vehicle_type[i]])
        # data['control_percentages'] = s


def _add_vehicle_input_column(data: pd.DataFrame,
                              vehicles_per_lane: int):
    if vehicles_per_lane is not None:
        data['vehicles_per_lane'] = int(vehicles_per_lane)


def _add_risk_column(data: pd.DataFrame,
                     accepted_risk: Union[int, None]):
    if accepted_risk is not None:
        data['accepted_risk'] = int(accepted_risk)


class DataReader(ABC):

    def __init__(self, scenario_name=None):
        self.scenario_name = scenario_name

    @abstractmethod
    def load_data(self, file_identifier):
        pass


class VissimDataReader(DataReader):
    """Base class to read data generated by VISSIM"""

    def __init__(self, scenario_name: str,
                 file_format: str, separator: str,
                 data_identifier: str, header_identifier: str,
                 header_map: dict):

        self.file_handler = FileHandler(scenario_name)
        # network_data_dir = self.file_handler.get_results_base_folder()
        DataReader.__init__(self, scenario_name)
        # self.vehicle_type = vehicle_type.name.lower()
        self.file_format = file_format
        self.separator = separator
        self.data_identifier = data_identifier
        self.header_identifier = header_identifier
        self.header_map = header_map

    # @staticmethod
    # def load_max_deceleration_data():
    #     """ Loads data describing maximum deceleration distribution per
    #     vehicle
    #      type and velocity
    #
    #     :return: pandas dataframe with double index
    #     """
    #     max_deceleration_data = pd.read_csv(os.path.join(
    #         vissim_networks_folder, 'max_decel_data.csv'))
    #     kph_to_mps = 1 / 3.6
    #     max_deceleration_data['vel'] = max_deceleration_data['vel']
    #     * kph_to_mps
    #     max_deceleration_data.set_index(['veh_type', 'vel'], inplace=True)
    #     return max_deceleration_data

    def load_data(self, file_identifier: Union[int, str],
                  n_rows: int = None) -> pd.DataFrame:
        """ Loads data from one file of a chosen network with given
        vehicle input and controlled vehicle percentage.
        Accepting None vehicle_type and vehicles_per_lane during testing phase

        :param file_identifier: File full path
        :param n_rows: Number of rows going to be read from the file.
         Used for debugging purposes.
        :return: pandas dataframe with the data
        """

        # full_address = self.create_full_file_address(
        #     file_identifier, vehicle_type, controlled_vehicles_percentage,
        #     vehicles_per_lane, accepted_risk)
        full_address = file_identifier
        try:
            with open(full_address, 'r') as file:
                # Skip header lines
                for line in file:
                    # In all VISSIM files, the data starts after a line such as
                    # '$VEHICLE:'. The variable names are listed after the ':'.
                    if line.startswith(self.header_identifier):
                        header_no_split = line
                        if ':' in header_no_split:
                            header_no_split = line.partition(':')[-1]
                        file_header = header_no_split.rstrip('\n').split(
                            self.separator)
                        break

                column_names = []
                for variable_name in file_header:
                    extra_info = ''
                    if '(' in variable_name:
                        opening_idx = variable_name.find('(')
                        closing_idx = variable_name.find(')')
                        extra_info = (
                            variable_name[opening_idx:closing_idx + 1])
                        variable_name = variable_name[:opening_idx]
                    try:
                        column_names.append(self.header_map[
                                                variable_name.lstrip(' ')]
                                            + extra_info)
                    except KeyError:
                        column_names.append(variable_name.lower() + extra_info)
                data = pd.read_csv(file, sep=self.separator,
                                   names=column_names, index_col=False,
                                   nrows=n_rows)
        except OSError:
            raise ValueError('No VISSIM file at {}'.format(file_identifier))

        data.dropna(axis='columns', how='all', inplace=True)

        # _add_vehicle_type_columns(data, vehicle_type,
        #                           controlled_vehicles_percentage)
        # _add_vehicle_input_column(data, vehicles_per_lane)
        # _add_risk_column(data, accepted_risk)
        return data

    def load_test_data(self):
        """
        Loads data inside the 'test' folder
        """
        return self.load_data(1)

    def load_data_with_controlled_percentage(
            self,
            vehicle_percentages: List[Dict[VehicleType, int]],
            vehicle_input: Union[int, List[int]],
            accepted_risks: List[int] = None
    ) -> pd.DataFrame:
        """
        Loads data from all simulations with the given autonomous
        percentages.

        :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulation.
        :param vehicle_input:
        :param accepted_risks: accepted lane change risk
        :return: pandas dataframe with the data
        """
        # percentage_copy = vehicle_percentage[:]
        if not isinstance(vehicle_input, list):
            vehicle_input = [vehicle_input]
        if accepted_risks is None:
            accepted_risks = [None]

        data_per_folder = []
        for vp in vehicle_percentages:
            for veh_input in vehicle_input:
                for ar in (accepted_risks if sum(vp.values()) > 0
                           else [0]):
                    min_file_number, max_file_number = (
                        self.file_handler.find_min_max_file_number(
                            self.data_identifier, self.file_format, vp,
                            veh_input, ar))
                    # Since files contain cumulative data from all runs
                    # in a set, we only need to read the latest file.
                    new_data = self.load_data_from_scenario(
                        max_file_number, vp, veh_input, ar)
                    # Files containing outputs from older simulations
                    # (earlier than Sept. 21 2021) might contain data
                    # from more simulations than just those indicated by
                    # the veh input folder name. Therefore we must drop
                    # some results.
                    if min_file_number != max_file_number:
                        drop_idx = new_data[
                            new_data['simulation_number']
                            < min_file_number].index
                        new_data.drop(drop_idx, inplace=True)
                    data_per_folder.append(new_data)
        data = pd.concat(data_per_folder, ignore_index=True)
        match_sim_number_to_random_seed(data)
        return data

    def load_data_from_several_files(
            self,
            vehicle_percentages: Dict[VehicleType, int],
            vehicles_per_lane: int,
            first_file_number: int,
            last_file_number: int,
            accepted_risk: int = None) -> pd.DataFrame:
        """Reads and aggregates data from several simulations with a given
        percentage of controlled vehicles.

        :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulation.
        :param vehicles_per_lane: Vehicle input per lane on VISSIM. Possible
         values depend on the controlled_vehicles_percentage: 500:500:2500
        :param first_file_number: simulation run number of the first file
        :param last_file_number: simulation run number of the last file
        :param accepted_risk: accepted lane change risk
        :return: single aggregated pandas dataframe """

        sim_output = []
        for i in range(first_file_number, last_file_number + 1):
            try:
                new_data = self.load_data_from_scenario(
                    i, vehicle_percentages,
                    vehicles_per_lane, accepted_risk)
                if 'simulation_number' not in new_data.columns:
                    new_data['simulation_number'] = i
                sim_output.append(new_data)
            except ValueError:
                warnings.warn('Tried to load simulations from {} to {}, '
                              'but stopped at {}'.
                              format(first_file_number, last_file_number, i))
                break

        return pd.concat(sim_output, ignore_index=True)

    def load_data_from_scenario(
            self, file_identifier: int,
            vehicle_percentages: Dict[VehicleType, int],
            vehicles_per_lane: int = None,
            accepted_risk: int = None,
            n_rows: int = None) -> pd.DataFrame:
        """
        Loads data from one file of a chosen network with given vehicle input
        and controlled vehicle percentage.

        :param file_identifier: An integer indicating the simulation number
        :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulation.
        :param vehicles_per_lane: Vehicle input per lane on VISSIM. Possible
         values depend on the controlled_vehicles_percentage: 500:500:2500
        :param accepted_risk: accepted lane change risk
        :param n_rows: Number of rows going to be read from the file.
         Used for debugging purposes.
        :return: pandas dataframe with the data
        """

        full_address = self._create_full_file_address(
            file_identifier, vehicle_percentages,
            vehicles_per_lane, accepted_risk)
        data = self.load_data(full_address, n_rows=n_rows)
        if 'simulation_number' not in data.columns:
            data['simulation_number'] = file_identifier
        _add_vehicle_type_columns(data, vehicle_percentages)
        _add_vehicle_input_column(data, vehicles_per_lane)
        _add_risk_column(data, accepted_risk)
        return data

    def _create_full_file_address(self, file_identifier: Union[int, str],
                                  vehicle_percentages: Dict[VehicleType, int],
                                  vehicles_per_lane: int,
                                  accepted_risk: int = None) -> str:
        """

        :param file_identifier: This can be either a integer indicating
         the simulation number or the file name directly
        :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulation.
        :param vehicles_per_lane: Vehicle input per lane on VISSIM. Possible
         values depend on the controlled_vehicles_percentage: 500:500:2500
        :param accepted_risk: accepted lane change risk
        :return: string with the full file address ready to be opened
        """
        if isinstance(file_identifier, str):
            file_name = file_identifier
        else:
            file_name = self._create_file_name(file_identifier)
        data_folder = self.file_handler.get_vissim_data_folder(
            vehicle_percentages, vehicles_per_lane, accepted_risk)
        return os.path.join(data_folder, file_name)

    def _create_file_name(self, file_identifier: int = None) -> str:
        network_file = self.file_handler.get_file_name()
        if file_identifier is not None:
            # Create a three-character string with trailing zeros and then
            # sim_nums (e.g.: _004, _015, _326)
            num_str = '_' + str(file_identifier).rjust(3, '0')
        else:
            num_str = ''
        file_name = (network_file + self.data_identifier
                     + num_str + self.file_format)
        return file_name

    @staticmethod
    def _keep_only_aggregated_data(data: pd.DataFrame):
        """
        Some files contains data aggregated for all vehicle categories and
        then detailed for each vehicle category. This method keeps only the
        aggregated data
        :param data: the data to be cleaned
        :return:
        """
        cols_to_be_dropped = []
        for name in data.columns:
            if '(' in name and name.split('(')[1][:-1] != 'ALL':
                cols_to_be_dropped.append(name)
        data.drop(columns=cols_to_be_dropped, inplace=True)
        # Remove (ALL) from the column names
        column_names = [name.split('(')[0] for name in data.columns]
        data.columns = column_names


class VehicleRecordReader(VissimDataReader):
    """Reads vehicle records generated by VISSIM"""

    _file_format = '.fzp'
    _separator = ';'
    _data_identifier = ''
    _header_identifier = '$VEHICLE'
    _header_map = {
        'SIMRUN': 'simulation_number', 'SIMSEC': 'time', 'NO': 'veh_id',
        'VEHTYPE': 'veh_type', 'LANE\\LINK\\NO': 'link',
        'LANE\\INDEX': 'lane', 'POS': 'x', 'SPEED': 'vx',
        'ACCELERATION': 'ax', 'POSLAT': 'y', 'LEADTARGNO': 'leader_id',
        'FOLLOWDIST': 'vissim_delta_x',
        'COORDFRONTX': 'front_x', 'COORDFRONTY': 'front_y',
        'COORDREARX': 'rear_x', 'COORDREARY': 'rear_y',
        'SPEEDDIFF': 'vissim_delta_v', 'LENGTH': 'length',
        'LNCHG': 'lane_change', 'GIVECONTROLTOVISSIM': 'vissim_control',
        'LEADTARGTYPE': 'target_type'
    }

    # Note: we don't necessarily want all the variables listed in each of the
    # map above

    def __init__(self, scenario_name):
        VissimDataReader.__init__(self, scenario_name,
                                  self._file_format, self._separator,
                                  self._data_identifier,
                                  self._header_identifier, self._header_map)

    def load_data_with_controlled_vehicles_percentage(
            self,
            vehicle_percentages: List[Dict[VehicleType, int]],
            vehicle_input: Union[int, List[int]],
            accepted_risks: List[int] = None
    ) -> pd.DataFrame:
        """
        :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulations.
        :param vehicle_input: Vehicles per lane per hour
        :param accepted_risks: Accepted risks for lane changing
        :returns: single dataframe with data from all simulations
        """
        a = input('Loading several vehicle records simultaneously might '
                  'consume too much memory.\nIt is recommended to use the '
                  'generate_data method instead.\nAre you sure you want to '
                  'continue? [y/n]')
        if a == 'y':
            return super().load_data_with_controlled_percentage(
                vehicle_percentages, vehicle_input, accepted_risks)
        raise RuntimeError

    def generate_data(self,
                      vehicle_percentages: Dict[VehicleType, int],
                      vehicle_inputs: List[int],
                      accepted_risk: int = None,
                      n_rows: int = None) -> (pd.DataFrame, int):
        """
        Yields all the vehicle record files for the chosen simulation scenario.

        :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulations.
        :param vehicle_inputs: Vehicle input per lane used in simulation.
        :param n_rows: Number of rows going to be read from the file.
         Used for debugging purposes.
        :param accepted_risk: accepted lane change risk
        :return:
        """
        # if vehicle_inputs is None:
        #     vehicle_inputs = self.get_all_vehicle_inputs_in_folder(
        #         vehicle_type, percentage)

        # Check all the *_vehs_per_lane folders in the percentage folder
        for veh_input in vehicle_inputs:
            min_file_number, max_file_number = (
                self.file_handler.find_min_max_file_number(
                    self.data_identifier, self.file_format,
                    vehicle_percentages, veh_input, accepted_risk))
            for file_number in range(min_file_number,
                                     max_file_number + 1):
                print('Loading file number {} / {}'.format(
                    file_number - min_file_number + 1,
                    max_file_number - min_file_number + 1))
                yield (self.load_data_from_scenario(
                    file_number, vehicle_percentages, veh_input,
                    accepted_risk, n_rows), file_number)


class DataCollectionReader(VissimDataReader):
    """Reads data generated from data collection measurements in VISSIM"""

    _file_format = '.att'
    _separator = ';'
    _data_identifier = '_Data Collection Results'
    _header_identifier = '$DATACOLLECTIONMEASUREMENTEVALUATION'
    _header_map = {
        'SIMRUN': 'simulation_number', 'TIMEINT': 'time_interval',
        'DATACOLLECTIONMEASUREMENT': 'sensor_number',
        'DIST': 'distance', 'VEHS': 'vehicle_count',
        'QUEUEDELAY': 'queue_delay', 'OCCUPRATE': 'occupancy_rate',
        'ACCELERATION': 'acceleration', 'LENGTH': 'length',
        'PERS': 'people count', 'SPEEDAVGARITH': 'speed_avg',
        'SPEEDAVGHARM': 'speed_harmonic_avg'
    }

    def __init__(self, scenario_name):
        VissimDataReader.__init__(self, scenario_name,
                                  self._file_format, self._separator,
                                  self._data_identifier,
                                  self._header_identifier, self._header_map)

    def load_data(self, file_identifier, n_rows: int = None) -> pd.DataFrame:
        """
        Loads data collection results from one file of a chosen network with
        given vehicle input  and controlled vehicle percentage.

        :param file_identifier: This can be either a integer indicating
         the simulation number or the file name directly
        :param n_rows: Number of rows going to be read from the file.
         Used for debugging purposes.
        :return: pandas dataframe with the data
        """

        data = super().load_data(file_identifier, n_rows)
        # We remove columns with information specific to a single vehicle
        # type. We only want the (ALL) columns
        VissimDataReader._keep_only_aggregated_data(data)
        # Include flow
        time_interval = data['time_interval'].iloc[0]
        data['flow'] = self._compute_flow(data['vehicle_count'], time_interval)
        return data

    @staticmethod
    def _compute_flow(vehicle_count: pd.Series, measurement_interval: str):
        interval_start, _, interval_end = measurement_interval.partition('-')
        measurement_period = int(interval_end) - int(interval_start)
        seconds_in_hour = 3600
        return seconds_in_hour / measurement_period * vehicle_count


class LinkEvaluationReader(VissimDataReader):
    """Reads data generated from link evaluation measurements in VISSIM"""

    _file_format = '.att'
    _separator = ';'
    _data_identifier = '_Link Segment Results'
    _header_identifier = '$LINKEVALSEGMENTEVALUATION'
    _header_map = {
        'SIMRUN': 'simulation_number', 'TIMEINT': 'time_interval',
        'LINKEVALSEGMENT': 'link_segment_number', 'DENSITY': 'density',
        'DELAYREL': 'delay_relative', 'SPEED': 'average_speed',
        'VOLUME': 'volume'
    }
    _data_to_ignore = 'emissions'

    def __init__(self, scenario_name):
        VissimDataReader.__init__(self, scenario_name,
                                  self._file_format, self._separator,
                                  self._data_identifier,
                                  self._header_identifier, self._header_map)

    def load_data(self, file_identifier, n_rows: int = None) -> pd.DataFrame:
        """
        Loads link evaluation outputs from one file of a chosen network with
        given vehicle input  and controlled vehicle percentage.

        :param file_identifier: This can be either a integer indicating
         the simulation number or the file name directly
        :param n_rows: Number of rows going to be read from the file.
         Used for debugging purposes.
        :return: pandas dataframe with the data
        """

        data = super().load_data(file_identifier, n_rows)
        # Some column names contain (ALL). We can remove that information
        # We remove columns with information specific to a single vehicle
        # type. We only want the (ALL) columns
        VissimDataReader._keep_only_aggregated_data(data)
        # Drop all the emissions columns
        cols_to_be_dropped = [name for name in data.columns
                              if name.startswith(self._data_to_ignore)]
        data.drop(columns=cols_to_be_dropped, inplace=True)
        link_information = data['link_segment_number'].str.split(
            '-', expand=True).astype(int)
        data['link_number'] = link_information.iloc[:, 0]
        data['link_length'] = (link_information.iloc[:, -1]
                               - link_information.iloc[:, -2])
        # If data was not exported per lane, we set all lanes to zero
        data['lane'] = (0 if link_information.shape[1] == 3 else
                        link_information.iloc[:, 1])

        # data['lane'] = (data['link_segment_number'].str.split('-').str[1].
        #                 astype(int))
        return data


class VissimLaneChangeReader(VissimDataReader):
    """Reads lane change data generated by VISSIM"""

    _file_format = '.spw'
    _separator = ';'
    _data_identifier = ''
    _header_identifier = 't; VehNo;'
    _header_map = {
        't': 'time', 'VehNo': 'veh_id', 'v [m/s]': 'vx',
        'Link No.': 'link', 'Lane': 'origin_lane', 'New Lane': 'dest_lane',
        'VF': 'lo_id', 'v VF [m/s]': 'lo_vx',
        'dv VF [m/s]': 'lo_delta_vx', 'dx VF [m]': 'lo_gap',
        'VB': 'fo_id', 'v VB': 'fo_vx',
        'dv VB [m/s]': 'fo_delta_vx', 'dx VB': 'fo_gap',
        'new VF': 'ld_id', 'v new VF [m/s]': 'ld_vx',
        'dv new VF [m/s]': 'ld_delta_vx', 'dx new VF [m]': 'ld_gap',
        'new VB': 'fd_id', 'v new VB [m/s]': 'fd_vx',
        'dv new VB [m/s]': 'fd_delta_vx', 'dx new VB [m]': 'fd_gap',
    }

    def __init__(self, scenario_name):
        VissimDataReader.__init__(self, scenario_name,
                                  self._file_format, self._separator,
                                  self._data_identifier,
                                  self._header_identifier, self._header_map)

    # def load_data(self, file_identifier, n_rows: int = None) -> pd.DataFrame:
    #     data = super().load_data(file_identifier, n_rows)
    #     data['simulation_number'] = file_identifier
    #     return data

    def load_data_with_controlled_percentage(
            self,
            vehicle_percentages: List[Dict[VehicleType, int]],
            vehicle_input: Union[int, List[int]],
            accepted_risks: List[int] = None) -> pd.DataFrame:
        """
        Returns None if no lane change file is found.
        :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulations.
        :param vehicle_input:
        :param accepted_risks: accepted lane change risk
        :return:
        """

        # percentage_copy = vehicle_percentage[:]
        if not isinstance(vehicle_input, list):
            vehicle_input = [vehicle_input]
        # desired_folders = set([str(vi) + '_vehs_per_lane'
        #                        for vi in vehicle_input])
        if accepted_risks is None:
            accepted_risks = [None]

        data_per_folder = []
        for vp in vehicle_percentages:
            for veh_input in vehicle_input:
                for ar in accepted_risks:
                    min_file_number, max_file_number = (
                        self.file_handler.find_min_max_file_number(
                            self.data_identifier, self.file_format, vp,
                            veh_input, ar))
                    if min_file_number > max_file_number:  # no file found
                        return pd.DataFrame()
                    new_data = self.load_data_from_several_files(
                        vp, veh_input, min_file_number,
                        max_file_number, ar)
                    data_per_folder.append(new_data)
        data = pd.concat(data_per_folder, ignore_index=True)
        match_sim_number_to_random_seed(data)
        return data


class LinkReader(VissimDataReader):
    _file_format = '.att'
    _separator = ';'
    _data_identifier = '_Links'
    _header_identifier = '$LINK'
    _header_map = {
        'NO': 'number', 'NAME': 'name', 'NUMLANES': 'number_of_lanes',
        'LENGTH2D': 'length', 'ISCONN': 'is_connector',
        'FROMLINK': 'from_link', 'TOLINK': 'to_link'
    }

    def __init__(self, scenario_name):
        VissimDataReader.__init__(self, scenario_name,
                                  self._file_format, self._separator,
                                  self._data_identifier,
                                  self._header_identifier, self._header_map)

    def load_data(self, file_identifier=None, n_rows=None) -> pd.DataFrame:
        link_file_folder = self.file_handler.get_network_file_folder()
        file_name = self._create_file_name()
        full_address = os.path.join(link_file_folder, file_name)
        data = super().load_data(full_address)
        return data


class VehicleInputReader(VissimDataReader):
    """Reads files containing simulation vehicle input """

    _file_format = '.att'
    _separator = ';'
    _data_identifier = '_Vehicle Inputs'
    _header_identifier = '$VEHICLEINPUT'
    _header_map = {'NO': 'number', 'NAME': 'name', 'LINK': 'link',
                   'VOLUME': 'vehicle_input', 'VEHCOMP': 'vehicle_composition'}

    def __init__(self, scenario_name):
        VissimDataReader.__init__(self, scenario_name,
                                  self._file_format, self._separator,
                                  self._data_identifier,
                                  self._header_identifier, self._header_map)

    # def load_data_with_controlled_vehicles_percentage(
    #         self, percentage: Union[int, List[int]]) -> pd.DataFrame:
    #     return super().load_data_with_controlled_vehicles_percentage(
    #         percentage)


class ReducedSpeedAreaReader(VissimDataReader):
    """Reads data from reduced speed areas used in a VISSIM simulation"""

    _file_format = '.att'
    _separator = ';'
    _data_identifier = '_Reduced Speed Areas'
    _header_identifier = '$REDUCEDSPEEDAREA'
    _header_map = {
        'NO': 'number', 'NAME': 'name', 'LANE': 'lane', 'POS': 'position',
        'LENGTH': 'length', 'TIMEFROM': 'time_from', 'TIMETO': 'time_to',
        'DESSPEEDDISTR': 'speed_limit', 'DECEL': 'max_approach_deceleration'
    }

    def __init__(self, scenario_name):
        VissimDataReader.__init__(self, scenario_name,
                                  self._file_format, self._separator,
                                  self._data_identifier,
                                  self._header_identifier, self._header_map)

    def load_data_with_controlled_percentage(self, vehicle_type,
                                             vehicle_percentage,
                                             vehicle_input=None,
                                             accepted_risks=None):
        print('Not yet coded.')
        return


class PostProcessedDataReader(DataReader):
    """
    Base class to read safety data extracted from vissim simulations
    """
    file_format = '.csv'
    data_identifier = ''

    def __init__(self, scenario_name: str, data_identifier: str):
        self.file_handler = FileHandler(scenario_name)
        DataReader.__init__(self, scenario_name)
        self.data_identifier = data_identifier

    def load_data(self, file_identifier: str) -> pd.DataFrame:
        """
        Loads data from one file of a chosen network with given
        vehicle input and controlled vehicle percentage

        :param file_identifier: File full path
        :return: pandas dataframe with the data
        """

        # vehicle_type = file_identifier
        # data_folder = self.file_handler.get_vissim_data_folder(
        #     vehicle_type, controlled_vehicles_percentage,
        #     vehicles_per_lane, accepted_risk)
        # network_file = self.file_handler.get_file_name()
        # file_name = (network_file + self.data_identifier + self.file_format)
        # full_address = os.path.join(data_folder, file_name)
        full_address = file_identifier
        try:
            data = pd.read_csv(full_address)
        except OSError:
            # Old format files end with a three digit number. Let's try to
            # read that before giving up
            network_file = self.file_handler.get_file_name()
            data_folder = os.path.dirname(full_address)
            file_name = self._load_file_starting_with_name(network_file,
                                                           data_folder)
            full_address = os.path.join(data_folder, file_name)
            data = pd.read_csv(full_address)

        # _add_vehicle_type_columns(data, vehicle_type,
        #                           controlled_vehicles_percentage)
        # _add_vehicle_input_column(data, vehicles_per_lane)
        # _add_risk_column(data, accepted_risk)
        return data

    def load_test_data(self):
        return self.load_data(self.file_handler.get_vissim_test_folder())

    def load_data_with_controlled_percentage(
            self, vehicle_percentages: List[Dict[VehicleType, int]],
            vehicle_input: Union[int, List[int]] = None,
            accepted_risks: List[int] = None
    ) -> pd.DataFrame:
        """
        Loads data from all simulations with the given autonomous
        percentages.

        :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulations.
        :param vehicle_input: Vehicles per hour per lane
        :param accepted_risks: Lane changing accepted risks
        :return:
        """
        # percentage_copy = vehicle_percentage[:]
        if not isinstance(vehicle_input, list):
            vehicle_input = [vehicle_input]
        if accepted_risks is None:
            accepted_risks = [None]

        data_per_folder = []
        for vp in vehicle_percentages:
            # vt = list(vp.keys())
            # p = list(vp.values())
            for veh_input in vehicle_input:
                relevant_risks = accepted_risks if sum(vp.values()) > 0 else [0]
                for ar in relevant_risks:
                    data_folder = self.file_handler.get_vissim_data_folder(
                        vp, veh_input, ar)
                    network_file = self.file_handler.get_file_name()
                    file_name = (network_file + self.data_identifier
                                 + self.file_format)
                    full_address = os.path.join(data_folder, file_name)
                    new_data = self.load_data(full_address)
                    _add_vehicle_type_columns(new_data, vp)
                    _add_vehicle_input_column(new_data, veh_input)
                    _add_risk_column(new_data, ar)
                    data_per_folder.append(new_data)
        data = pd.concat(data_per_folder, ignore_index=True)
        match_sim_number_to_random_seed(data)
        return data

    def _load_file_starting_with_name(self, network_file, data_folder):
        base_name = network_file + self.data_identifier
        file_with_longer_name = []
        for file in os.listdir(data_folder):
            file_str = os.fsdecode(file)
            if file_str.startswith(base_name):
                file_with_longer_name.append(file_str)
        if len(file_with_longer_name) > 1:
            raise OSError('Too many possible files starting with {} '
                          'at {} found'.format(self.data_identifier,
                                               data_folder))
        if len(file_with_longer_name) == 0:
            raise OSError('No {} file at {}'.format(self.data_identifier,
                                                    data_folder))
        return file_with_longer_name[0]


class SSMDataReader(PostProcessedDataReader):
    """Reads aggregated SSM data obtained after processing vehicle record
    data"""

    _data_identifier = '_SSM Results'

    def __init__(self, scenario_name):
        PostProcessedDataReader.__init__(self, scenario_name,
                                         self._data_identifier)

    def load_data(self, file_identifier) -> pd.DataFrame:
        """

        :param file_identifier: file full path
        :return: SSM data for the requested simulation
        """
        data = super().load_data(file_identifier)
        # Ensure compatibility with previous naming convention
        data.rename(columns={'exact_risk': 'risk'}, inplace=True)
        data.rename(columns={
            'exact_risk_no_lane_change': 'risk_no_lane_change'}, inplace=True)
        return data


class RiskyManeuverReader(PostProcessedDataReader):
    _data_identifier = '_Risky Maneuvers'

    def __init__(self, scenario_name):
        PostProcessedDataReader.__init__(self, scenario_name,
                                         self._data_identifier)


class LaneChangeReader(PostProcessedDataReader):
    _data_identifier = '_Lane Changes'

    def __init__(self, scenario_name):
        PostProcessedDataReader.__init__(self, scenario_name,
                                         self._data_identifier)

    def load_data(self, file_identifier: str) -> pd.DataFrame:
        data = super().load_data(file_identifier)
        y = 'total_risk'
        data['total_lane_change_risk'] = (data[y + '_lo'] + data[y + '_ld']
                                          + data[y + '_fd'])
        y = 'initial_risk'
        data[y] = data[y + '_to_lo'] + data[y + '_to_ld'] + data[y + '_to_fd']

        # TODO: temporary [Oct 27, 22]. I saved the file path instead of the
        #  simulation number
        if isinstance(data['simulation_number'].iloc[0], str):
            data['simulation_number'] = (
                data['simulation_number'].str.split('.').str[0].str[-3:].
                astype(int))

        return data


class LaneChangeIssuesReader(PostProcessedDataReader):
    _data_identifier = '_Lane Change Issues'

    def __init__(self, scenario_name):
        PostProcessedDataReader.__init__(self, scenario_name,
                                         self._data_identifier)


class ViolationsReader(PostProcessedDataReader):
    _data_identifier = '_Traffic Light Violations'

    def __init__(self, scenario_name):
        PostProcessedDataReader.__init__(self, scenario_name,
                                         self._data_identifier)


class DiscomfortReader(PostProcessedDataReader):
    _data_identifier = '_Discomfort'

    def __init__(self, scenario_name):
        PostProcessedDataReader.__init__(self, scenario_name,
                                         self._data_identifier)


class NGSIMDataReader(DataReader):
    """Reads raw vehicle trajectory data from NGSIM scenarios on the US-101"""

    file_extension = '.csv'
    ngsim_dir = ('C:\\Users\\fvall\\Documents\\Research\\TrafficSimulation'
                 '\\NGSIM_original\\')
    location_switch = {'us-101': 'US-101-LosAngeles-CA\\us-101-vehicle'
                                 '-trajectory-data'}
    interval_switch = {1: '0750am-0805am', 2: '0805am-0820am',
                       3: '0820am-0835am'}
    ngsim_to_reader_naming = {'Global_Time': 'time', 'Vehicle_ID': 'veh_id',
                              'v_Class': 'veh_type', 'Local_Y': 'x',
                              'v_Vel': 'vx', 'Local_X': 'y',
                              'Preceding': 'leader_id', 'Lane_ID': 'lane',
                              'Space_Hdwy': 'delta_x', 'v_Length': 'length'}
    relevant_columns = {'time', 'veh_id', 'veh_type', 'link', 'lane',
                        'x', 'vx', 'y', 'leader_id', 'delta_x', 'leader_type',
                        'front_x', 'front_y', 'rear_x', 'rear_y', 'length',
                        'delta_v', 'lane_change'}

    def __init__(self, location):
        # self.interval = 0
        try:
            self.data_dir = os.path.join(self.ngsim_dir,
                                         self.location_switch[location])
            file_name = 'trajectories-'
        except KeyError:
            print('{}: KeyError: location {} not defined'.
                  format(self.__class__.__name__, location))
            self.data_dir = None
            file_name = None
        DataReader.__init__(self, file_name)
        self.data_source = 'NGSIM'

    def load_data(self, file_identifier=1):

        if file_identifier not in self.interval_switch:
            print('Requested interval not available')
            return pd.DataFrame()

        # self.interval = interval
        file_name = self.scenario_name + self.interval_switch[file_identifier]
        full_address = os.path.join(self.data_dir,
                                    file_name + self.file_extension)
        try:
            with open(full_address, 'r') as file:
                data = pd.read_csv(file)
                data.rename(columns=self.ngsim_to_reader_naming, inplace=True)
        except OSError:
            raise ValueError('No NGSIM file with name {}'.format(file_name))

        self.select_relevant_columns(data)
        return data

    # def get_simulation_identifier(self):
    #     """Returns the time of the day of the data which was loaded last"""
    #     return self.interval_switch[self.interval]

    @staticmethod
    def select_relevant_columns(data):
        columns_to_drop = []
        for col in data.columns:
            if col not in NGSIMDataReader.relevant_columns:
                columns_to_drop.append(col)
        data.drop(columns=columns_to_drop, inplace=True)


class SyntheticDataReader(DataReader):
    file_extension = '.csv'
    data_dir = ('C:\\Users\\fvall\\Documents\\Research\\TrafficSimulation'
                '\\synthetic_data\\')
    synthetic_sim_name = 'synthetic_data'

    def __init__(self):
        self.sim_number = 0
        self.column_names = ['time', 'veh_id', 'veh_type', 'link', 'lane', 'x',
                             'vx', 'y', 'leader_id', 'delta_x']
        DataReader.__init__(self, self.synthetic_sim_name)
        self.data_source = 'synthetic'

    def load_data(self, file_identifier=None):
        file_name = self.scenario_name
        full_address = os.path.join(self.data_dir,
                                    file_name + self.file_extension)
        with open(full_address, 'r') as file:
            data = pd.read_csv(file)
        NGSIMDataReader.select_relevant_columns(data)
        return data

    def load_test_data(self):
        return self.load_data()


class TrafficLightSourceReader:
    _file_extension = '.csv'
    _data_identifier = '_source_times'

    def __init__(self, scenario_name: str):
        file_handler = FileHandler(scenario_name)
        file_name = (file_handler.get_file_name()
                     + self._data_identifier + self._file_extension)
        self._file_address = os.path.join(
            file_handler.get_network_file_folder(), file_name)

    def load_data(self) -> pd.DataFrame:
        tl_data = pd.read_csv(self._file_address)
        if 'starts_red' not in tl_data.columns:
            tl_data['starts_red'] = True
        tl_data['cycle_time'] = (
                tl_data['red duration']
                + tl_data['green duration']
                + tl_data['amber duration'])
        return tl_data


class SignalControllerFileReader(DataReader):
    _file_extension = '.sig'

    def __init__(self, scenario_name):
        DataReader.__init__(self, scenario_name)
        self.file_handler = FileHandler(scenario_name)

    def load_data(self, file_identifier: int) -> ET.ElementTree:
        """

        :param file_identifier: Indicates the id of the signal controller
        :return:
        """
        file_address = self.file_handler.get_network_file_folder()
        file_name = self.file_handler.get_file_name()
        full_address = os.path.join(file_address,
                                    file_name + str(file_identifier)
                                    + self._file_extension)
        try:
            with open(full_address, 'r') as file:
                return ET.parse(file)
        except OSError:
            raise ValueError('File {} not found'.format(full_address))


class MovesDataReader(DataReader):
    """ Class to read from Excel files generated by MOVES """

    _file_extension = '.xls'

    def __init__(self, scenario_name: str, data_identifier: str,
                 sheet_name: str):
        DataReader.__init__(self, scenario_name)
        self.data_identifier = data_identifier
        self.sheet_name = sheet_name
        self.file_handler = file_handling.FileHandler(scenario_name)

    def load_data(self, file_identifier=None) -> pd.DataFrame:
        folder = self.file_handler.get_moves_default_data_folder()
        # file_name = (self.file_handler.get_file_name()
        #              + '_MOVES_' + self.data_identifier
        #              + self._file_extension)
        file_name = self.data_identifier + self._file_extension
        full_address = os.path.join(folder, file_name)
        if file_identifier is None:
            data = pd.read_excel(full_address, sheet_name=self.sheet_name)
        else:
            data = pd.read_excel(full_address, sheet_name=file_identifier)
        return data

    # def get_data_from_all_sheets(self) -> Dict[str, pd.DataFrame]:
    #     folder = self.file_handler.get_moves_data_folder()
    #     file_name = (self.file_handler.get_file_name()
    #                  + '_MOVES_' +
    #                  self.data_identifier
    #                  + self._file_extension)
    #     full_address = os.path.join(folder, file_name)
    #     data = pd.read_excel(full_address, sheet_name=None)
    #     return data


class MovesLinkReader(MovesDataReader):

    _data_identifier = 'links'
    _sheet_name = 'link'

    def __init__(self, scenario_name: str):
        MovesDataReader.__init__(self, scenario_name, self._data_identifier,
                                 self._sheet_name)

    def get_count_id(self) -> int:
        data = self.load_data('County')
        return data['countyID'].iloc[0]

    def get_zone_id(self) -> int:
        data = self.load_data('Zone')
        return data['zoneID'].iloc[0]

    def get_road_id(self) -> int:
        data = self.load_data('RoadType')
        return data.loc[data['roadDesc'] == 'Urban Restricted Access',
                        'roadTypeID'].iloc[0]

    def get_off_road_id(self) -> int:
        data = self.load_data('RoadType')
        return data.loc[data['roadDesc'] == 'Off-Network',
                        'roadTypeID'].iloc[0]


class MovesLinkSourceReader(MovesDataReader):

    _data_identifier = 'linksource'
    _sheet_name = 'linkSourceTypeHour'

    def __init__(self, scenario_name: str):
        MovesDataReader.__init__(self, scenario_name, self._data_identifier,
                                 self._sheet_name)

    def get_passenger_vehicle_id(self) -> int:
        data = self.load_data('SourceUseType')
        return data.loc[data['sourceTypeName'] == 'Passenger Car',
                        'sourceTypeID'].iloc[0]


class MOVESDatabaseReader:
    user = 'moves'
    port = 3307
    hostname = '127.0.0.1'
    _vehicle_type_str_map = {
        VehicleType.HUMAN_DRIVEN: 'hdv',
        VehicleType.ACC: 'acc',
        VehicleType.AUTONOMOUS: 'av',
        VehicleType.CONNECTED: 'cav'
    }

    def __init__(self, scenario_name: str):
        with open('db_password.txt', 'r') as f:
            self.password = f.readline()
        self.scenario_name = scenario_name
        self.file_handler = file_handling.FileHandler(scenario_name)

    def load_data(self, vehicle_percentages: Dict[VehicleType, int],
                  vehicles_per_lane: int,
                  accepted_risk: int = None) -> pd.DataFrame:
        temp = []
        for vt in vehicle_percentages:
            p = vehicle_percentages[vt]
            p_str = str(p) if p < 100 else ''
            if p > 0:
                temp.append(self._vehicle_type_str_map[vt] + p_str)
        if not temp:
            temp.append(self._vehicle_type_str_map[VehicleType.HUMAN_DRIVEN])
        vt_str = '_'.join(sorted(temp))
        # Sample name: highway_in_and_out_hdv_6000_out
        output_database = '_'.join([self.file_handler.get_file_name(),
                                    vt_str, str(3 * vehicles_per_lane), 'out'])
        input_database = '_'.join([self.file_handler.get_file_name(),
                                   vt_str, str(3 * vehicles_per_lane), 'in'])
        data = self._load_pollutants(output_database)
        self._add_volume_data(input_database, data)
        _add_vehicle_type_columns(data, vehicle_percentages)
        _add_vehicle_input_column(data, vehicles_per_lane)
        _add_risk_column(data, accepted_risk)
        data['emission_per_volume'] = data['emission'] / data['volume']
        return data

    def load_data_with_controlled_percentage(
            self, vehicle_percentages: List[Dict[VehicleType, int]],
            vehicle_input: Union[int, List[int]],
            accepted_risks: List[int] = None
    ) -> pd.DataFrame:
        """
        Loads data from all simulations with the given autonomous
        percentages.

        :param vehicle_percentages: List of dictionnaries describing the
         types of controlled vehicles in each simulation.
        :param vehicle_input:
        :param accepted_risks: accepted lane change risk
        :return: pandas dataframe with the data
        """
        if not isinstance(vehicle_input, list):
            vehicle_input = [vehicle_input]
        if accepted_risks is None:
            accepted_risks = [None]

        data_per_folder = []
        for i in vehicle_input:
            for vp in vehicle_percentages:
                for ar in accepted_risks:
                    data_per_folder.append(self.load_data(vp, i, ar))
        data = pd.concat(data_per_folder, ignore_index=True)
        return data

    def _load_pollutants(self, output_database: str):
        conn = mariadb.connect(
            user=self.user,
            password=self.password,
            host=self.hostname,
            port=self.port,
            database=output_database
        )
        cur = conn.cursor()
        # We assume the latest run contains the correct results
        max_run_id_query = ("(SELECT MAX(MOVESRunID) FROM "
                            + output_database + ".movesoutput)")
        sql_query = ("SELECT roadTypeID, pollutantID, sum(emissionQuant) "
                     "FROM " + output_database + ".movesoutput "
                     "WHERE MOVESRunID = " + max_run_id_query + " "
                     "GROUP BY roadTypeID, pollutantID")
        cur.execute(sql_query)

        data = {'pollutant_id': [], 'emission': [], 'road_type': []}
        for roadTypeID, pollutantID, emmissionQuant in cur:
            data['pollutant_id'].append(pollutantID)
            data['emission'].append(emmissionQuant)
            data['road_type'].append(roadTypeID)
        conn.close()
        return pd.DataFrame(data=data)

    def _add_volume_data(self, input_database: str, data: pd.DataFrame):
        conn = mariadb.connect(
            user=self.user,
            password=self.password,
            host=self.hostname,
            port=self.port,
            database=input_database
        )
        cur = conn.cursor()
        volume_query = ("SELECT roadTypeID, sum(linkVolume) "
                        "FROM " + input_database + ".link "
                                                   "GROUP BY roadTypeID")
        cur.execute(volume_query)
        data['volume'] = 0
        for roadTypeID, linkVolume in cur:
            data.loc[data['road_type'] == roadTypeID, 'volume'] = linkVolume
        conn.close()
        data.drop(data[data['volume'] == 0].index, inplace=True)
