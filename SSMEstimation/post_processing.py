import time
from abc import ABC, abstractmethod
from collections import defaultdict
import warnings
# import time
from typing import Dict, List, Tuple, Union

import numpy as np
import pandas as pd
from scipy.stats import truncnorm

import data_writer
from file_handling import FileHandler
import readers
from vehicle import PlatoonLaneChangeStrategy, Vehicle, VehicleType

# ============================== Constants =================================== #
# TODO: determine highway or traffic light from network_info dictionary in
#  file_handling file
HIGHWAY_SCENARIOS = {'in_and_out', 'in_and_merge', 'i710', 'us101'}
TRAFFIC_LIGHT_SCENARIOS = {'traffic_lights'}
data_source_VISSIM = 'vissim'
data_source_NGSIM = 'ngsim'
data_source_SYNTHETIC = 'synthetic'

km_to_mile = 0.6213712


# =============================== Functions ================================== #

def find_percent_variation(value_1: float, value_2: float) -> float:
    return (value_2 - value_1) / value_1 * 100


def post_process_data(data_source: str,
                      vehicle_records: pd.DataFrame):
    """Post processing includes:
     - Computing relative velocity and bumper to bumper distance to leader,
     - Adding leader type
     - Converting all data to SI units
    :param data_source: vissim, ngsim or synthetic
    :param vehicle_records: detailed vehicle states over time
    :return: nothing, it alters the data in place"""

    if data_source.lower() == data_source_VISSIM:
        post_process_vissim_vehicle_record(vehicle_records)
    elif data_source.lower() == data_source_NGSIM:
        post_process_ngsim_data(vehicle_records)
    elif data_source == data_source_SYNTHETIC:
        post_process_synthetic_data(vehicle_records)
    else:
        print('[DataPostProcessor] Trying to process data from unknown '
              'data source.')
        return


def post_process_vissim_vehicle_record(vehicle_records):
    """
    Process fzp vehicle record data file generated by VISSIM
    :return: None
    """
    # veh_data = self.veh_records

    kph_to_mps = 1 / 3.6
    vehicle_records['vx'] = vehicle_records['vx'] * kph_to_mps

    # warm_up_time = 60
    # DataPostProcessor.remove_early_samples(vehicle_records, warm_up_time)

    # When the vehicle is stopping due to a traffic light, we consider it
    # has no leader
    if 'target_type' in vehicle_records.columns:
        signal_ahead_idx = vehicle_records['target_type'] == 'Signal head'
        vehicle_records.loc[signal_ahead_idx, 'leader_id'] = np.nan
    # By convention, if vehicle has no leader, we set it as its own leader
    vehicle_records['leader_id'].fillna(vehicle_records['veh_id'],
                                        inplace=True, downcast='infer')
    # Compute relative velocity to the vehicle's leader (own vel minus
    # leader vel) Note: we need this function because VISSIM output
    # 'SpeedDiff' is not always correct. It has been observed to equal
    # the vehicle's own speed at the previous time step.
    compute_values_relative_to_leader(data_source_VISSIM, vehicle_records)


def post_process_ngsim_data(vehicle_records):
    """
    Process csv data file generated from NGSIM
    :return: None
    """
    # vehicle_record = self.veh_records
    integer_columns = {'veh_id': int, 'leader_id': int,
                       'veh_type': int, 'lane': int}
    vehicle_records.astype(integer_columns, copy=False)

    columns_in_feet = ['x', 'y', 'vx', 'length', 'delta_x']
    foot_to_meter = 0.3048
    vehicle_records[columns_in_feet] *= foot_to_meter

    base_time = min(vehicle_records['time'])
    # From milliseconds to deciseconds
    vehicle_records['time'] = (vehicle_records['time'] - base_time) // 100
    vehicle_records.sort_values(by=['time', 'veh_id'], inplace=True)
    # Define warm up time as the first moment some vehicle has a leader
    warm_up_time = min(vehicle_records.loc[vehicle_records['leader_id'] > 0,
                                           'time'])
    remove_early_samples_from_vehicle_records(warm_up_time, vehicle_records)
    # By convention, if vehicle has no leader, we set it as its own leader
    no_leader_idx = vehicle_records['leader_id'] == 0
    vehicle_records.loc[no_leader_idx,
                        'leader_id'] = vehicle_records['veh_id']

    vehicle_records['delta_x_old'] = vehicle_records[
        'delta_x']  # for checks

    compute_values_relative_to_leader(
        data_source_NGSIM, vehicle_records)


def post_process_synthetic_data(vehicle_records):
    """
    Process csv file synthetically generated
    :return: None
    """
    vehicle_records.sort_values(by='time', inplace=True)
    # compute_values_relative_to_leader(
    #     data_source_SYNTHETIC, vehicle_records)


def compute_values_relative_to_leader(data_source: str,
                                      vehicle_records: pd.DataFrame):
    """
    Computes bumper to bumper distance and relative speed to preceding
    vehicle, and adds the preceding vehicle type.
    """

    # vehicle_records = self.veh_records
    total_samples = vehicle_records.shape[0]
    print('Adding distance, relative speed and leader type for {} '
          'samples'.format(total_samples))

    percent = 0.1
    out_of_bounds_idx = []
    grouped_by_time = vehicle_records.groupby('time')
    delta_v = np.zeros(total_samples)
    leader_type = np.zeros(total_samples)
    distance = np.zeros(total_samples)
    counter = 0
    for _, current_data in grouped_by_time:
        veh_idx = current_data['veh_id'].to_numpy()
        leader_idx = current_data['leader_id'].to_numpy()
        min_idx = min(veh_idx)
        max_idx = max(veh_idx)
        n_vehicles = max_idx - min_idx + 1
        vel_vector = np.zeros(n_vehicles)
        type_vector = np.zeros(n_vehicles)

        # If leader is not in the current time, we proceed as if there
        # was no leader (happens more often with NGSIM data)
        out_of_bounds_check = current_data['leader_id'] > max_idx
        if np.any(out_of_bounds_check):
            # Save the indices with issues to correct the original
            # dataframe after the loop
            out_of_bounds_idx.extend(list(out_of_bounds_check.
                                          index[out_of_bounds_check]))
            # Then correct the indices for this loop iteration
            leader_idx[out_of_bounds_check] = veh_idx[out_of_bounds_check]

        adjusted_idx = veh_idx - min_idx
        adjusted_leader_idx = leader_idx - min_idx
        vel_vector[adjusted_idx] = current_data['vx']
        delta_v[counter:counter + current_data.shape[0]] = (
                vel_vector[adjusted_idx] - vel_vector[adjusted_leader_idx])

        type_vector[adjusted_idx] = current_data['veh_type']
        leader_type[counter:counter + current_data.shape[0]] = (
            type_vector[adjusted_leader_idx])

        distance[counter:counter + current_data.shape[0]] = (
            compute_distance_to_leader(data_source, current_data,
                                       adjusted_idx, adjusted_leader_idx))
        counter += current_data.shape[0]

        if counter >= percent * total_samples:
            print('{:.0f}%'.format(counter / total_samples * 100), end=',')
            percent += 0.1
    print()  # skip a line
    vehicle_records['delta_v'] = delta_v
    vehicle_records['leader_type'] = leader_type
    vehicle_records['delta_x'] = distance

    if len(out_of_bounds_idx) > 0:
        vehicle_records.loc[out_of_bounds_idx, 'leader_id'] = (
            vehicle_records.loc[out_of_bounds_idx, 'veh_id'])
        print('Found {} instances of leaders outside the simulation'.
              format(len(out_of_bounds_idx)))


def create_simulation_summary_test(network_name: str):
    """
    Short version of create_simulation_summary to make running tests easier
    :return:
    """
    # MUST BE UPDATED
    pass
    # ssm_names = ['low_TTC', 'high_DRAC', 'risk',
    #              'risk_no_lane_change']
    # risk_name = 'risk'
    # pp = [
    #     PostProcessor(network_name, None, 'ssm', ssm_names),
    #     PostProcessor(network_name, None, 'risky_maneuvers',
    #                   risk_name)
    # ]
    #
    # vehicle_record_reader = readers.VehicleRecordReader(network_name)
    # print('Testing safety summary creation for network {}'.format(network_name))
    # data = defaultdict(list)
    # vehicle_records = vehicle_record_reader.load_test_data()
    # post_process_data(data_source_VISSIM, vehicle_records)
    # for single_pp in pp:
    #     print('Computing', single_pp.data_name)
    #     data[single_pp.data_name].append(single_pp.post_process(
    #         vehicle_records))
    # print('-' * 79)
    #
    # for single_pp in pp:
    #     print('Saving ', single_pp.data_name)
    #     all_simulations_data = pd.concat(data[single_pp.data_name])
    #     single_pp.writer.save_as_csv(all_simulations_data, None, None)


def create_summary_traffic_light_simulations(
        vehicle_percentages: Dict[VehicleType, int],
        vehicle_inputs: List[int] = None,
        debugging: bool = False):
    """Reads multiple vehicle record data files, postprocesses them,
    computes and aggregates SSMs results, extracts risky maneuvers, and
    find traffic light violations. SSMs, risky maneuvers and
    violations are saved as csv files per vehicle input.

    :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulations.
    :param vehicle_inputs: Vehicle inputs for which we want SSMs
     computed. Default value is None, which means we'll read all available
     inputs.
    :param debugging: If true, we load only 10^5 samples from the vehicle
     records and do not save results.
    :return: Nothing. SSM results are saved to as csv files"""

    network_name = 'traffic_lights'
    check_already_processed_vehicle_inputs(
        network_name, vehicle_percentages,
        vehicle_inputs)

    pp = [SSMProcessor(network_name),
          RiskyManeuverProcessor(network_name),
          ViolationProcessor(network_name),
          DiscomfortProcessor(network_name)]

    vehicle_record_reader = readers.VehicleRecordReader(network_name)
    n_rows = 10 ** 5 if debugging else None
    for vi in vehicle_inputs:
        print('Start of safety summary creation for network {}, vehicle '
              'percentages {}, and input {}'.format(
            network_name, vehicle_percentages, vi))
        data_generator = vehicle_record_reader.generate_data(
            vehicle_percentages, vi, n_rows=n_rows)

        data = defaultdict(list)
        for (vehicle_records, file_number) in data_generator:
            post_process_data(data_source_VISSIM, vehicle_records)
            for single_pp in pp:
                print('Computing', single_pp.data_name)
                data[single_pp.data_name].append(single_pp.post_process(
                    vehicle_records))
            print('-' * 79)

        if not debugging:
            for single_pp in pp:
                print('Saving ', single_pp.data_name)
                all_simulations_data = pd.concat(data[single_pp.data_name])
                all_simulations_data['vehicles_per_lane'] = vi
                single_pp.writer.save_as_csv(all_simulations_data,
                                             vehicle_percentages, vi)


def create_summary_with_risks(scenario_name: str,
                              vehicle_percentages: Dict[VehicleType, int],
                              vehicle_inputs: List[int],
                              accepted_risks: List[int] = None,
                              debugging: bool = False,
                              post_processors: List[str] = None,
                              analyze_lane_change: bool = True):
    """
    Reads multiple vehicle record data files, postprocesses them,
    computes and aggregates SSMs results, extracts risky maneuvers, and
    find traffic light violations. SSMs, risky maneuvers and
    violations are saved as csv files per vehicle input.

    :param scenario_name: Currently available: in_and_out, in_and_merge,
     i710, us101, traffic_lights
    :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulations.
    :param vehicle_inputs: Vehicle inputs for which we want SSMs
     computed.
    :param accepted_risks: Accepted lane change risk.
    :param debugging: If true, we load only 10^5 samples from the vehicle
     records and do not save results.
    :param post_processors: Defines which post processing operations should be
     done. Used for debugging. Default value of None will perform all
     available operations. [NOT IMPLEMENTED]
    :param analyze_lane_change: If true, computes risks of every reported
     lane change
    :return: Nothing. Results are saved to as csv files
    """

    if accepted_risks is None:  # simulations without risk as a variable
        accepted_risks = [None]
    elif sum(vehicle_percentages.values()) == 0:  # avoid repeating the same
        # computation for scenarios that vary risk but without AVs
        accepted_risks = [0]

    pp = [
        SSMProcessor(scenario_name),
        # RiskyManeuverProcessor(scenario_name),
        LaneChangeIssuesProcessor(scenario_name),
        # DiscomfortProcessor(scenario_name)
    ]

    lane_change_reader = readers.VissimLaneChangeReader(scenario_name)
    vehicle_record_reader = readers.VehicleRecordReader(scenario_name)
    n_rows = 10 ** 5 if debugging else None
    for vi in vehicle_inputs:
        for ar in accepted_risks:
            print('Start of safety summary creation for network {}, vehicle '
                  'percentages {}, input {}, risk {}'.format(
                   scenario_name, vehicle_percentages, vi, ar))
            data_generator = vehicle_record_reader.generate_data(
                vehicle_percentages, vi, accepted_risk=ar, n_rows=n_rows)

            data = defaultdict(list)
            for (vehicle_records, file_number) in data_generator:
                # post_process_data(data_source_VISSIM, vehicle_records)
                for single_pp in pp:
                    print('Computing', single_pp.data_name)
                    data[single_pp.data_name].append(single_pp.post_process(
                        vehicle_records))
                if analyze_lane_change:
                    vissim_lane_change_data = (
                        lane_change_reader.load_data_from_scenario(
                            file_number, vehicle_percentages, vi, ar))
                    lane_change_data = complement_lane_change_data(
                        scenario_name, vehicle_records, vissim_lane_change_data)
                    data['lane_change'].append(lane_change_data)
                print('-' * 79)

            if not debugging:
                for single_pp in pp:
                    print('Saving ', single_pp.data_name)
                    all_simulations_data = pd.concat(data[single_pp.data_name])
                    all_simulations_data['vehicles_per_lane'] = vi
                    single_pp.writer.save_as_csv(all_simulations_data,
                                                 vehicle_percentages, vi,
                                                 accepted_risk=ar)
                if analyze_lane_change:
                    lc_writer = data_writer.LaneChangeWriter(scenario_name)
                    all_simulations_data = pd.concat(data['lane_change'])
                    all_simulations_data['vehicles_per_lane'] = vi
                    lc_writer.save_as_csv(all_simulations_data,
                                          vehicle_percentages, vi,
                                          accepted_risk=ar)


def find_lane_change_issues(network_name: str,
                            vehicle_percentages: Dict[VehicleType, int],
                            vehicle_inputs: List[int],
                            accepted_risks: List[int] = None):
    """
    Looks for cases of vehicles that were either removed from the simulation
    for waiting too long for a lane change or AVs which gave control to vissim.

    :param network_name:
    :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulations.
    :param vehicle_inputs:
    :param accepted_risks:
    :return:
    """

    if accepted_risks is None:  # simulations without risk as a variable
        accepted_risks = [None]
    elif sum(vehicle_percentages.values()) == 0:  # avoid repeating the same
        # computation for scenarios that vary risk but without AVs
        accepted_risks = [0]
    pp = LaneChangeIssuesProcessor(network_name)
    vehicle_record_reader = readers.VehicleRecordReader(network_name)
    for vi in vehicle_inputs:
        for ar in accepted_risks:
            data_generator = vehicle_record_reader.generate_data(
                vehicle_percentages, vi, accepted_risk=ar)
            data = defaultdict(list)
            for (vehicle_records, file_number) in data_generator:
                data[pp.data_name].append(pp.post_process(vehicle_records))
            all_simulations_data = pd.concat(data[pp.data_name])
            all_simulations_data['vehicles_per_lane'] = vi
            pp.writer.save_as_csv(all_simulations_data, vehicle_percentages,
                                  vi, ar)


def create_time_in_minutes_from_intervals(data: pd.DataFrame):
    """ Creates a 'time' column in minutes

    :param data: data aggregated over time intervals
    """
    # Create time in minutes for better display
    seconds_in_minute = 60
    data['time'] = data['time_interval'].apply(
        lambda x: int(x.split('-')[0]) / seconds_in_minute)


def save_safety_files(vehicle_input: int,
                      writers: List[data_writer.PostProcessedDataWriter],
                      data: List[List[pd.DataFrame]],
                      vehicle_percentages: Dict[VehicleType, int]):
    """

    :param vehicle_input:
    :param writers:
    :param data:
    :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulations.
    :return:
    """
    print('Files with input ', vehicle_input, ' done. Saving to file...')
    for i in range(len(writers)):
        writers[i].save_as_csv(pd.concat(data[i]), vehicle_percentages,
                               vehicle_input)
    print('Successfully saved.')


def check_human_take_over(network_name: str,
                          vehicle_percentages: Dict[VehicleType, int],
                          vehicle_inputs: List[int],
                          accepted_risk: List[int] = None):
    """Reads multiple vehicle record data files to check how often the
    autonomous vehicles gave control back to VISSIM

    :param network_name: Network name. Either the actual file name or the
     network nickname. Currently available: in_and_out, in_and_merge, i710,
     us101
    :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulations.
    :param vehicle_inputs: simulation vehicle inputs to be checked
    :param accepted_risk: Accepted lane change risk
    :return: Nothing.
    """

    if accepted_risk is None:
        accepted_risk = [None]

    vehicle_record_reader = readers.VehicleRecordReader(network_name)
    for vi in vehicle_inputs:
        print('Input:', vi)
        for ar in accepted_risk:
            print(' Accepted risk: ', ar)
            n_blocked_vehs = []
            data_generator = vehicle_record_reader.generate_data(
                vehicle_percentages, vi, accepted_risk=ar
            )
            for (vehicle_records, _) in data_generator:
                # Since the scenarios have at most one mandatory lane change,
                # we assume each vehicle only gives control to VISSIM at
                # most once
                blocked_vehs = vehicle_records.loc[
                    (vehicle_records['vissim_control'] == 1)
                    & (vehicle_records['veh_type'] != Vehicle.VISSIM_CAR_ID),
                    'veh_id'].unique()
                n_blocked_vehs.append(blocked_vehs.shape[0])
                # print('Total blocked vehicles: ', blocked_vehs.shape[0])
            print('  Mean # of blocked vehicles: {}'.format(np.mean(
                n_blocked_vehs)))


def find_removed_vehicles(network_name: str,
                          vehicle_percentages: Dict[VehicleType, int],
                          vehicles_per_lane: List[int],
                          accepted_risk: List[int] = None):
    """Checks whether VISSIM removed any vehicles for standing still too
    long.
    Results obtained so far:
    - in_and_out with no controlled vehicles and highest inputs (2000 and
    2500) had no vehicles removed. """

    if accepted_risk is None:
        accepted_risk = [None]
    exit_links = [5, 6]

    vehicle_record_reader = readers.VehicleRecordReader(network_name)
    for vi in vehicles_per_lane:
        print('Input:', vi)
        for ar in accepted_risk:
            print(' Accepted risk: ', ar)
            n_removed_vehicles = []
            data_generator = vehicle_record_reader.generate_data(
                vehicle_percentages, vi, accepted_risk=ar
            )
            for (vehicle_records, _) in data_generator:
                max_time = vehicle_records.iloc[-1]['time']
                last_entry_per_veh = vehicle_records.groupby('veh_id').last()
                removed_vehs = last_entry_per_veh.loc[
                    ~(last_entry_per_veh['link'].isin(exit_links))
                    & (last_entry_per_veh['time'] < max_time)].index
                n_removed_vehicles.append(len(removed_vehs))
                print('  {} removed vehs'.format(n_removed_vehicles[-1]))
            print(' Mean # of removed vehicles: {}'.format(np.mean(
                n_removed_vehicles)))


def add_main_ssms(vehicle_records: pd.DataFrame, ssm_names: List[str]):
    ssm_estimator = SSMEstimator(vehicle_records)
    for ssm in ssm_names:
        ssm_estimator.include_ssm_by_name(ssm)
    # if network_name in ['in_and_out', 'i710', 'us101']:
    #     ssm_estimator.include_ttc()
    #     ssm_estimator.include_drac()
    #     for choice in [False, True]:
    #         ssm_estimator.include_collision_free_gap(
    #             consider_lane_change=choice)
    #         ssm_estimator.include_risk(consider_lane_change=choice)
    # elif network_name in ['traffic_lights']:
    #     ssm_estimator.include_barrier_function_risk()


def create_time_bins_and_labels(period, vehicle_records):
    """Creates equally spaced time intervals, generates labels
    that go with them and includes a time_interval column to the
    dataframe.

    :param vehicle_records: vehicle records data loaded from VISSIM
    :param period: time interval length
    :return: None; alters the data in place"""
    final_time = int(vehicle_records['time'].iloc[-1])
    interval_limits = []
    interval_labels = []
    for i in range(0, final_time + period,
                   period):
        interval_limits.append(i)
        interval_labels.append(str(i) + '-'
                               + str(i + period))
    vehicle_records['time_interval'] = pd.cut(
        x=vehicle_records['time'], bins=interval_limits,
        labels=interval_labels[:-1])


def check_already_processed_vehicle_inputs(
        network_name: str, vehicle_percentages: Dict[VehicleType, int],
        vehicle_input_per_lane: List[int]):
    """
    Checks if the scenario being post processed was processed before.
    Prints a message if yes.
    :param network_name: Currently available: in_and_out, in_and_merge,
     i710, us101, traffic_lights
    :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulations.
    :param vehicle_input_per_lane: number of vehicles entering the simulation
      per hour
    :return: nothing. Just prints a message on the console.
    """
    ssm_reader = readers.SSMDataReader(network_name)
    try:
        ssm_data = ssm_reader.load_data_in_bulk(
            [vehicle_percentages], vehicle_input_per_lane)
    except OSError:
        return
    # if not ssm_data.empty:
    processed_vehicle_inputs = ssm_data['vehicles_per_lane'].unique()
    for v_i in (set(vehicle_input_per_lane) & set(processed_vehicle_inputs)):
        print('FYI: SSM results for network {}, vehicle percentages {}, '
              'and input {} already exist. They are '
              'being recomputed.'.
              format(network_name, vehicle_percentages, v_i))


def compute_distance_to_leader(data_source: str, veh_data: pd.DataFrame,
                               adjusted_idx: np.array,
                               adjusted_leader_idx: np.array):
    """
    Computes the longitudinal distance between a vehicle's front
    bumper to the rear bumper of the leading vehicle
    :param data_source: vissim, ngsim or synthetic
    :param veh_data: vehicle data during a single time step
    :param adjusted_idx: vehicle indices starting from zero
    :param adjusted_leader_idx: leader indices starting from zero
    """
    n = np.max(adjusted_idx) + 1
    if data_source == data_source_VISSIM:

        front_x_vector = np.zeros(n)
        front_y_vector = np.zeros(n)
        rear_x_vector = np.zeros(n)
        rear_y_vector = np.zeros(n)

        front_x_vector[adjusted_idx] = veh_data['front_x']
        rear_x_vector[adjusted_idx] = veh_data['rear_x']
        front_y_vector[adjusted_idx] = veh_data['front_y']
        rear_y_vector[adjusted_idx] = veh_data['rear_y']
        distance = compute_gap_between_vehicles(
            rear_x_vector[adjusted_leader_idx],
            rear_y_vector[adjusted_leader_idx],
            front_x_vector[adjusted_idx],
            front_y_vector[adjusted_idx])
        # distance = np.sqrt((rear_x_vector[adjusted_leader_idx]
        #                     - front_x_vector[adjusted_idx]) ** 2
        #                    + (rear_y_vector[adjusted_leader_idx]
        #                       - front_y_vector[adjusted_idx]) ** 2)
        # Set gap to zero when there's no leader
        distance[adjusted_idx == adjusted_leader_idx] = 0

    elif data_source == data_source_NGSIM:
        length = np.zeros(n)
        length[adjusted_idx] = veh_data['length']
        leader_length = length[adjusted_leader_idx]
        distance = veh_data['delta_x'] - leader_length
    else:
        distance = veh_data['delta_x']

    return distance


def compute_gap_between_vehicles(leader_rear_x, leader_rear_y,
                                 follower_front_x, follower_front_y):
    return np.sqrt((leader_rear_x - follower_front_x) ** 2
                   + (leader_rear_y - follower_front_y) ** 2)


def remove_early_samples_from_vehicle_records(vehicle_records: pd.DataFrame,
                                              warm_up_time: float):
    """Remove samples with time below some warm up time

    :param vehicle_records: vehicle records loaded from VISSIM
    :param warm_up_time: time below which samples are removed"""

    veh_data = vehicle_records
    below_warmup = veh_data.loc[veh_data['time'] <= warm_up_time].index
    print('Removing {} warm up time samples'.format(len(below_warmup)))
    veh_data.drop(index=below_warmup, inplace=True)


def remove_early_samples_from_sensors(data: pd.DataFrame, warmup_time: int):
    """
    Removes samples from link evaluation and data collection output files.

    :param data: the dataframe containing the data
    :param warmup_time: time, in minutes, below which samples are removed
    :returns: nothing; alters data in place
    """
    data['interval_init_time'] = (data['time_interval'].str.split('-').str[
                                      0].astype(int))
    data.drop(index=data[data['interval_init_time'] < warmup_time * 60].index,
              inplace=True)


# TODO [nov 8, 2022]: can probably replace the two preceeding functions
def drop_warmup_samples(data: pd.DataFrame, warmup_time: int):
    """
    Drops samples with time below warmup time.
    :param data: Any VISSIM output or post processed data
    :param warmup_time: Time *in minutes*
    """
    warmup_time *= 60
    if 'time' not in data.columns:
        create_time_in_minutes_from_intervals(data)
        data['time'] *= 60
    data.drop(index=data[data['time'] < warmup_time].index, inplace=True)


# ========================= Interfacing with MOVES =========================== #

def get_individual_vehicle_trajectories_to_moves(
        scenario_name: str,
        vehicles_per_lane: int,
        vehicle_percentages: Dict[VehicleType, int],
        accepted_risk: int = None,
        first_minute: int = 15,
        vehs_per_simulation: int = 1):
    """
    Finds the first vehicle entering the simulation link after the cut
    off minute and save its info in MOVES format
    """

    accepted_links = {4, 10000, 10004}
    last_minute = 20
    first_second = first_minute * 60
    interval = (last_minute - first_minute) * 60 / vehs_per_simulation
    link_reader = readers.LinkReader(scenario_name)
    vissim_link_data = link_reader.load_data()
    relevant_links = vissim_link_data[vissim_link_data['length'] > 20]
    relevant_link_ids = relevant_links['number'].to_numpy()
    link_id_map = dict(zip(relevant_links['number'],
                           [i for i in range(relevant_links.shape[0])]))

    init_link_number = 0
    vehicle_record_reader = readers.VehicleRecordReader(scenario_name)
    data_generator = vehicle_record_reader.generate_data(
        vehicle_percentages, vehicles_per_lane, accepted_risk=accepted_risk)
    link_data_list = []
    speed_data_list = []
    for (vehicle_records, _) in data_generator:
        vehicle_records['secondID'] = np.floor(vehicle_records['time']).astype(
            int)
        creation_time_and_link = vehicle_records.groupby('veh_id').agg(
            {'time': 'min', 'link': 'first'})
        for i in range(vehs_per_simulation):
            cut_off_second = first_second + i * interval
            veh_id = creation_time_and_link[
                (creation_time_and_link['time'] >= cut_off_second)
                & creation_time_and_link['link'].isin(accepted_links)].index[0]
            vehicle_data = vehicle_records[vehicle_records['veh_id'] == veh_id]

            single_veh_link_data = _fill_moves_link_data_from_vissim_links(
                scenario_name, relevant_links, vehicle_data)
            single_veh_link_data['linkID'] = (
                    single_veh_link_data['linkID'].map(link_id_map)
                    + init_link_number)

            single_veh_speed_data = _create_moves_speeds_from_vehicle_record(
                vehicle_data, relevant_link_ids)
            single_veh_speed_data['secondID'] -= cut_off_second
            single_veh_speed_data['linkID'] = (
                    single_veh_speed_data['linkID'].map(link_id_map)
                    + init_link_number)

            init_link_number = single_veh_link_data['linkID'].max() + 1
            speed_data_list.append(single_veh_speed_data)
            link_data_list.append(single_veh_link_data)

    moves_link_data = pd.concat(link_data_list)
    moves_speed_data = pd.concat(speed_data_list)
    moves_link_source_data = _fill_moves_link_source_data(
        scenario_name, moves_link_data['linkID'])

    # Add mandatory Off-road link
    last_row = moves_link_data.iloc[-1]
    moves_link_data.loc[max(moves_link_data.index) + 1] = [
        last_row['linkID'].max() + 1, last_row['countyID'],
        last_row['zoneID'], 1, 0, 0, 0, 0, 0]

    # Save all files
    link_writer = data_writer.MOVESLinksWriter(scenario_name)
    link_writer.save_data(moves_link_data, vehicle_percentages,
                          vehicles_per_lane, accepted_risk)
    link_source_writer = data_writer.MOVESLinkSourceWriter(scenario_name)
    link_source_writer.save_data(moves_link_source_data,
                                 vehicle_percentages,
                                 vehicles_per_lane, accepted_risk)
    drive_sched_writer = data_writer.MOVESLinkDriveWriter(scenario_name)
    drive_sched_writer.save_data(moves_speed_data, vehicle_percentages,
                                 vehicles_per_lane, accepted_risk)


def translate_links_from_vissim_to_moves(
        scenario_name: str,
        vehicles_per_lane: int,
        vehicle_percentages: Dict[VehicleType, int],
        accepted_risk: int = None,
        platoon_lane_change_strategy: PlatoonLaneChangeStrategy = None,
        orig_and_dest_lane_speeds: Tuple[int, int] = None,
        warmup_minutes: int = 10):
    """
    Reads link evaluation output files from VISSIM and write link,
    link source and drive schedule xls files for use in MOVES
    """

    # Load VISSIM data
    link_evaluation_reader = readers.LinkEvaluationReader(scenario_name)
    link_evaluation_data = (
        link_evaluation_reader.load_data_in_bulk(
            [vehicle_percentages], vehicles_per_lane, [accepted_risk],
            [platoon_lane_change_strategy], [orig_and_dest_lane_speeds])
    )
    remove_early_samples_from_sensors(link_evaluation_data, warmup_minutes)

    # We will pretend each simulation is a new set of links to avoid having to
    # run MOVES over and over again.
    n_links_per_simulation = len(link_evaluation_data['link_number'].unique())
    link_evaluation_data['link_id'] = (
            (link_evaluation_data['simulation_number'] - 1)
            * n_links_per_simulation + link_evaluation_data['link_number'])
    link_evaluation_data.sort_values('link_id', kind='stable', inplace=True,
                                     ignore_index=True)

    # Aggregated data files
    aggregated_link_data = link_evaluation_data.groupby('link_id')[[
        'link_id', 'link_length', 'volume', 'average_speed']].mean()
    moves_link_data = _fill_moves_link_data_from_link_evaluation_data(
        scenario_name, aggregated_link_data)
    link_writer = data_writer.MOVESLinksWriter(scenario_name)
    link_writer.save_data(moves_link_data, vehicle_percentages,
                          vehicles_per_lane, accepted_risk)

    # Set all sources
    moves_link_source_data = _fill_moves_link_source_data(
        scenario_name, aggregated_link_data['link_id'])
    link_source_writer = data_writer.MOVESLinkSourceWriter(scenario_name)
    link_source_writer.save_data(moves_link_source_data,
                                 vehicle_percentages,
                                 vehicles_per_lane, accepted_risk)

    # Get the speeds for each link per second
    drive_sched = _create_moves_speeds_from_link_evaluation(
        link_evaluation_data)
    drive_sched_writer = data_writer.MOVESLinkDriveWriter(scenario_name)
    drive_sched_writer.save_data(drive_sched, vehicle_percentages,
                                 vehicles_per_lane, accepted_risk)


def _fill_moves_link_data_from_link_evaluation_data(
        scenario_name: str,
        link_evaluation_data: pd.DataFrame) -> pd.DataFrame:
    # We will pretend each simulation is a different link to avoid having to
    # run MOVES over and over again
    moves_link_reader = readers.MovesLinkReader(scenario_name)
    county_id = moves_link_reader.get_count_id()
    zone_id = moves_link_reader.get_zone_id()
    road_type_id = moves_link_reader.get_road_id()
    off_net_id = moves_link_reader.get_off_road_id()
    moves_link_data = pd.DataFrame()

    moves_link_data['linkID'] = link_evaluation_data['link_id']
    moves_link_data['countyID'] = county_id
    moves_link_data['zoneID'] = zone_id
    moves_link_data['roadTypeID'] = road_type_id
    moves_link_data['linkLength'] = (link_evaluation_data['link_length']
                                     / 1000 * km_to_mile)
    moves_link_data['linkVolume'] = np.round(link_evaluation_data['volume'])
    moves_link_data['linkAvgSpeed'] = (
            link_evaluation_data['average_speed'] * km_to_mile)
    moves_link_data['linkDescription'] = 0
    moves_link_data['linkAvgGrade'] = 0
    # Add one off-network link
    moves_link_data.loc[max(moves_link_data.index) + 1] = [
        moves_link_data['linkID'].max() + 1, county_id, zone_id, off_net_id,
        0, 0, 0, 0, 0]
    return moves_link_data


def _fill_moves_link_data_from_vissim_links(
        scenario_name: str, link_data: pd.DataFrame,
        vehicle_data: pd.DataFrame):
    used_links = vehicle_data['link'].unique()
    used_links_idx = link_data[link_data['number'].isin(
        used_links)].index

    moves_link_reader = readers.MovesLinkReader(scenario_name)
    county_id = moves_link_reader.get_count_id()
    zone_id = moves_link_reader.get_zone_id()
    road_type_id = moves_link_reader.get_road_id()
    moves_link_data = pd.DataFrame()
    avg_speed_per_link = vehicle_data.groupby('link')['vx'].mean()
    # moves_link_data['linkID'] = (link_data.loc[used_links_idx, 'number'].
    #                              reset_index().index)
    moves_link_data['linkID'] = link_data.loc[used_links_idx, 'number']
    # moves_link_data.drop(columns='link_number', inplace=True)
    moves_link_data['countyID'] = county_id
    moves_link_data['zoneID'] = zone_id
    moves_link_data['roadTypeID'] = road_type_id
    moves_link_data['linkLength'] = (link_data.loc[used_links_idx, 'length']
                                     / 1000 * km_to_mile).to_numpy()
    moves_link_data['linkVolume'] = 1
    temp = moves_link_data[['linkID']].merge(avg_speed_per_link,
                                             left_on='linkID',
                                             right_index=True)
    moves_link_data['linkAvgSpeed'] = temp['vx'] * km_to_mile
    moves_link_data['linkDescription'] = 0
    moves_link_data['linkAvgGrade'] = 0
    return moves_link_data


def _fill_moves_link_source_data(scenario_name: str,
                                 link_ids: pd.Series) -> pd.DataFrame:
    # NOTE: for now we're only dealing with cars
    moves_link_source_reader = readers.MovesLinkSourceReader(scenario_name)
    car_id = moves_link_source_reader.get_passenger_vehicle_id()
    link_ids.name = 'linkID'
    moves_link_source_data = pd.DataFrame(link_ids)
    moves_link_source_data['sourceTypeID'] = car_id
    moves_link_source_data['sourceTypeHourFraction'] = 1
    return moves_link_source_data


def _create_moves_speeds_from_link_evaluation(
        link_evaluation_data: pd.DataFrame) -> pd.DataFrame:
    # Create the Moves-matching data. We consider the speed constant during
    # the interval
    interval_str = link_evaluation_data['time_interval'].iloc[0].split('-')
    interval_duration = int(interval_str[1]) - int(interval_str[0])
    drive_sched = pd.DataFrame(np.repeat(link_evaluation_data[[
        'link_id', 'average_speed']].to_numpy(), interval_duration, axis=0))
    drive_sched.columns = ['linkID', 'speed']
    drive_sched.reset_index(drop=True, inplace=True)
    drive_sched['speed'] *= km_to_mile
    drive_sched['linkID'] = drive_sched['linkID'].astype(int)
    first_link = drive_sched['linkID'].iloc[0]
    samples_per_link = np.count_nonzero(drive_sched['linkID'] == first_link)
    drive_sched['secondID'] = (drive_sched.index + 1 -
                               (drive_sched['linkID'] - first_link)
                               * samples_per_link).astype(int)
    drive_sched['grade'] = 0
    return drive_sched


def _create_moves_speeds_from_vehicle_record(
        vehicle_data: pd.DataFrame, link_ids: List) -> pd.DataFrame:
    speed_data = vehicle_data.groupby(
        'secondID', as_index=False).agg({'link': 'first', 'vx': 'mean'})
    speed_data.drop(index=speed_data[~speed_data['link'].isin(link_ids)].index,
                    inplace=True)
    # speed_data.drop(index=speed_data[speed_data['link'].isin(short_links)],
    #                 inplace=True)
    speed_data['grade'] = 0
    speed_data['vx'] *= km_to_mile
    speed_data.rename(
        columns={'link': 'linkID', 'vx': 'speed'}, inplace=True)
    return speed_data


# ============================= Traffic Lights =============================== #

def find_traffic_light_violations_all(
        network_name: str,
        vehicle_percentages: Dict[VehicleType, int],
        vehicle_inputs: List[int] = None,
        debugging: bool = False):
    """
    Reads multiple vehicle record data files, looks for cases of
    traffic light violation, and records them in a new csv file

    :param network_name: only network with traffic lights is traffic_lights
    :param vehicle_percentages: Describes the percentages of controlled
         vehicles in the simulations.
    :param vehicle_inputs: Vehicle inputs for which we want SSMs
     computed. If None (default), computes SSMs for all simulated vehicle
     inputs.
    :param debugging: If true, we load only 10^5 samples from the vehicle
     records and do not save results.
    :return: Nothing. Violation results are saved to as csv files"""

    violation_pp = ViolationProcessor(network_name)

    violations_list = []
    vehicle_record_reader = readers.VehicleRecordReader(network_name)
    n_rows = 10 ** 6 if debugging else None
    for vi in vehicle_inputs:
        data_generator = vehicle_record_reader.generate_data(
            vehicle_percentages, vi, n_rows=n_rows)
        for (vehicle_records, file_number) in data_generator:
            violations_list.append(
                violation_pp.post_process(vehicle_records))
    violations = pd.concat(violations_list)
    violation_pp.writer(network_name)
    violation_pp.writer.save_as_csv(violations, vehicle_percentages, 0)


# ========================= Lane change methods ============================== #

def complement_lane_change_data(network_name: str,
                                vehicle_record: pd.DataFrame,
                                vissim_lc_data: pd.DataFrame,
                                # risky_maneuver_data: pd.DataFrame
                                ) -> pd.DataFrame:
    """
    Add lane change crossing and end times, and initial and total risks to
    surrounding vehicles to the lane change data.

    :param network_name: network name
    :param vehicle_record: vehicle records of a single simulation
    :param vissim_lc_data: data for all lane changes during the simulation
    :return: Data with new columns
    """

    # Steps that can be done on the entire dataframe:
    vissim_lc_data.drop(index=(
        vissim_lc_data[vissim_lc_data['time'] + 5
                       > vehicle_record['time'].iloc[-1]]).index,
                        inplace=True)
    remove_false_lane_change_starts(vehicle_record, vissim_lc_data)
    lc_data = add_overlooked_lane_changes(vehicle_record, vissim_lc_data)
    print('Getting lane change attributes. {} from LC file, {} total'.format(
          vissim_lc_data.shape[0], lc_data.shape[0]))
    lc_data['lc_direction'] = lc_data['dest_lane'] - lc_data['origin_lane']
    if np.any(lc_data['lc_direction'].abs() > 1):
        warnings.warn('Vehicle changing two lanes at a time?',
                      RuntimeWarning)
        lc_data['lc_direction'] /= lc_data['lc_direction'].abs()
    vehicle_record['relative_vy'] = vehicle_record['y'].diff()
    add_vehicle_types_to_lc_data(vehicle_record, lc_data)
    label_lane_changes(network_name, vehicle_record, lc_data)

    # Steps that require checking the data of each lane change in detail
    data_by_veh = vehicle_record.groupby('veh_id')
    new_data = []
    notes = []
    max_comf_brake = [-i for i in range(4, 9)]
    # fd_discomfort = {'fd_discomfort_' + str(-i): [] for i in max_comf_brake}
    # times = np.zeros(4)
    # TODO: slow loop. Not sure we can avoid iterating over rows, but some
    #  functions can probably be optimized.
    for i, single_lc_data in lc_data.iterrows():
        # print(i)
        lc_veh_data = data_by_veh.get_group(single_lc_data['veh_id'])
        fd_data = (data_by_veh.get_group(single_lc_data['fd_id']) if
                   single_lc_data['fd_id'] > 0 else pd.DataFrame())
        # start_time = time.perf_counter()
        tc, tf = get_lane_change_crossing_and_end_times(lc_veh_data,
                                                        single_lc_data)
        # times[0] += time.perf_counter() - start_time
        # start_time = time.perf_counter()
        note = check_surrounding_vehicle_changes(vehicle_record,
                                                 single_lc_data, tc, tf)
        # times[1] += time.perf_counter() - start_time
        # start_time = time.perf_counter()
        risk_lo, risk_ld, risk_fd = compute_initial_lane_change_risks(
            single_lc_data)
        # times[2] += time.perf_counter() - start_time
        # start_time = time.perf_counter()

        # if risk_lo > 0 or risk_ld > 0 or risk_fd > 0:
        #     print('some risk')

        total_risk_lo, total_risk_ld, total_risk_fd = (
            get_risks_during_lane_change(lc_veh_data, fd_data,
                                         single_lc_data, tf))
        # get_total_lane_change_risk(
        #     risky_maneuver_data, single_lc_data, tf))
        # times[3] += time.perf_counter() - start_time

        vissim_in_control = lc_veh_data.loc[
            lc_veh_data['time'] == single_lc_data['time'],
            'vissim_control'].iloc[0]
        fd_discomfort = compute_fd_discomfort(fd_data, single_lc_data,
                                              max_comf_brake)
        # [fd_discomfort['fd_discomfort_' + str(-max_comf_brake[i])].append(
        #     temp[i]) for i in range(len(max_comf_brake))]

        new_data.append([tc, tf, risk_lo, risk_ld, risk_fd,
                         total_risk_lo, total_risk_ld, total_risk_fd,
                         vissim_in_control])
        new_data[-1].extend(fd_discomfort)
        notes.append(note)
    # print(times)
    columns = ['crossing_time', 'end_time', 'initial_risk_to_lo',
               'initial_risk_to_ld', 'initial_risk_to_fd',
               'total_risk_lo', 'total_risk_ld', 'total_risk_fd',
               'vissim_in_control']
    [columns.append('fd_discomfort_' + str(-i)) for i in max_comf_brake]
    lc_data[columns] = new_data
    lc_data['note'] = notes
    return lc_data.dropna()


def add_vehicle_types_to_lc_data(veh_data: pd.DataFrame,
                                 lc_data: pd.DataFrame):
    """
    Adds vehicle type information to the lane change data. This is useful to
    make computations faster later on.

    :param veh_data: vehicle records of a single simulation
    :param lc_data: data for all lane changes during the simulation
    :return:
    """
    veh_types = veh_data.groupby('veh_id')['veh_type'].first()
    veh_types[0] = 0
    lc_data['veh_type'] = veh_types[lc_data['veh_id']].to_numpy()
    lc_data['lo_type'] = veh_types[lc_data['lo_id']].to_numpy()
    lc_data['ld_type'] = veh_types[lc_data['ld_id']].to_numpy()
    try:
        lc_data['fd_type'] = veh_types[lc_data['fd_id']].to_numpy()
    except KeyError:
        all_ids = veh_data['veh_id'].unique()
        missing_ids = set([i for i in range(1, np.max(all_ids))]).difference(
            all_ids)
        print("Can't find fd in veh data. Missing ids: ", missing_ids)
        print("While issue is not addressed, let's remove these lane changes.")
        for m_id in missing_ids:
            lc_data.drop(index=lc_data[lc_data['fd_id'] == m_id].index,
                         inplace=True)
        lc_data['fd_type'] = veh_types[lc_data['fd_id']].to_numpy()


def remove_false_lane_change_starts(veh_data: pd.DataFrame,
                                    lane_change_data: pd.DataFrame):
    """
    With the controlled vehicles, VISSIM's lane change record has some false
    positives. We double check in the vehicle record if the lane change is
    actually taking place.

    :param veh_data:
    :param lane_change_data:
    :return: (intended) Nothing. The lane change dataframe is altered in place
    """
    merged_data = lane_change_data[['time', 'veh_id']].merge(
        veh_data[['time', 'veh_id', 'lane_change']], on=['time', 'veh_id'])
    remove_idx = merged_data[merged_data['lane_change'] == 'None'].index
    lane_change_data.drop(index=remove_idx, inplace=True)


def add_overlooked_lane_changes(veh_data: pd.DataFrame,
                                vissim_lane_change_data: pd.DataFrame):
    """
    Add lane changes not logged by VISSIM in the lane change file. This
    happens often with autonomous lane changes.
    """
    # Note: we could do this using only the vehicle record and ignoring the
    # lane change data from VISSIM. However, using VISSIM's lane change
    # record saves some time.

    # Check if the vehicle data has already been processed. If not, convert
    # from km/h to m/s and 'mark' as processed.
    if veh_data['leader_id'].isna().any():
        veh_data['leader_id'].fillna(veh_data['veh_id'],
                                     inplace=True, downcast='infer')
        veh_data['vx'] /= 3.6  # km/h->m/s

    # Find all the lane changes in the vehicle records data
    veh_data_sorted = veh_data.sort_values('veh_id', kind='stable')
    veh_data_sorted['absolute_lane'] = get_absolute_lane(
        veh_data_sorted['lane'], veh_data_sorted['link'])
    veh_data_sorted['is_lane_changing'] = (veh_data_sorted['lane_change']
                                           != 'None')
    veh_data_sorted['lc_transition'] = (veh_data_sorted['is_lane_changing'].
                                        diff().fillna(False))
    lc_data = (veh_data_sorted.loc[veh_data_sorted[
        'lc_transition']].iloc[::2])

    # Look for lane changes in lc_data but not in the lane_change_data
    intermediary_df = lc_data.merge(vissim_lane_change_data,
                                    on=['time', 'veh_id'], how='left',
                                    indicator=True)
    missing_lane_changes = lc_data.reset_index()[
        intermediary_df['_merge'] == 'left_only']
    # Look for the details of each lane change. No idea of how to do this
    # without a loop
    new_data = []
    filler_series = pd.Series(data=[0, 0, 0, 0, 0, 0, 0, 0],
                              index=['veh_id', 'vx', 'rear_x', 'front_x',
                                     'rear_y', 'front_y', 'delta_v', 'delta_x']
                              ).astype('int')
    for i, lc in missing_lane_changes.iterrows():
        data_now = veh_data_sorted[veh_data_sorted['time'] == lc['time']]

        try:
            lo_data = data_now[(data_now['veh_id'] == lc['leader_id'])
                               & (data_now['leader_id'] != lc['veh_id'])
                               ].iloc[0]
        except IndexError:
            lo_data = filler_series
        try:
            fo_data = data_now[(data_now['leader_id'] == lc['veh_id'])
                               & (data_now['veh_id'] != lc['leader_id'])
                               ].iloc[0]
        except IndexError:
            fo_data = filler_series
        # Note: this will not work in networks with several multi lane links
        dest_lane = lc['lane'] + (1 if lc['lane_change'] == 'Left' else -1)
        absolute_dest_lane = lc['absolute_lane'] + (
            1 if lc['lane_change'] == 'Left' else -1)
        dest_lane_data = data_now[data_now['absolute_lane']
                                  == absolute_dest_lane]
        gaps = dest_lane_data['front_x'] - lc['front_x']
        try:
            ld_data = dest_lane_data.loc[gaps[gaps > 0].idxmin()]
        except ValueError:  # there are no gaps > 0
            ld_data = filler_series
        try:
            fd_data = dest_lane_data.loc[gaps[gaps < 0].idxmax()]
        except ValueError:  # there are no gaps < 0
            fd_data = filler_series

        new_row = [lc['time'], lc['veh_id'], lc['vx'], lc['link'],
                   lc['lane'], dest_lane]
        for nearby_vehicle in [lo_data, fo_data, ld_data, fd_data]:
            if nearby_vehicle['front_x'] > lc['front_x']:
                leader, follower = nearby_vehicle, lc
            else:
                leader, follower = lc, nearby_vehicle
            inter_vehicle_gap = compute_gap_between_vehicles(
                leader['rear_x'], leader['rear_y'],
                follower['front_x'], follower['front_y'])
            new_row.extend(
                [nearby_vehicle['veh_id'], nearby_vehicle['vx'],
                 lc['vx'] - nearby_vehicle['vx'], inter_vehicle_gap])
        new_data.append(new_row)
    new_df = pd.DataFrame(data=new_data,
                          columns=vissim_lane_change_data.columns[:len(
                              new_data[0])])
    links = vissim_lane_change_data['link'].unique()
    new_df.drop(index=new_df[~new_df['link'].isin(links)].index, inplace=True)

    ret_df = pd.concat([vissim_lane_change_data, new_df],
                       ignore_index=True).fillna(method='ffill')
    return ret_df.sort_values('time')


def get_absolute_lane(lane: pd.Series, link: pd.Series):
    """
    Makes the lane number independent of the link. The links with only two
    lanes have 'absolute lanes' equal to 2 and 3. The method only works with
    the basic in and out lanes scenario.
    """
    absolute_lane = lane.copy()
    absolute_lane[link.isin({4, 6, 10002})] += 1
    return absolute_lane


def get_lane_change_crossing_and_end_times(single_veh_data,
                                           lc_data: pd.Series) -> (float,
                                                                   float):
    """

    :param single_veh_data: single vehicle data during simulation
    :param lc_data: data for a single lane change
    :return: lane change crossing time and end time
    """
    # veh_filter = veh_data['veh_id'] == lc_data['veh_id']
    # single_veh_data = veh_data.loc[veh_filter]
    # single_veh_data = veh_data.get_group(lc_data['veh_id'])
    if (lc_data['time'] + 5) > single_veh_data['time'].iloc[-1]:
        return float('nan'), float('nan')

    time_filter = single_veh_data['time'] >= lc_data['time']
    # We cannot simply check veh_data['lane'] == dest_lane because the
    # crossing and end times might happen at a transition between links
    crossing_time = single_veh_data.loc[
        time_filter
        & (lc_data['lc_direction'] * (single_veh_data['y'] - 0.5) < 0),
        'time'].iloc[0]
    # We can't just check veh_data['lane_change'] because values in this
    # column become None while the vehicle still has lateral speed.
    # Sometimes AVs don't go all the way to the middle of the dest lane. In
    # these cases we check when it stopped changing its lateral position
    end_time_candidate_1 = single_veh_data.loc[
        time_filter & (single_veh_data['time'] > crossing_time)
        & (lc_data['lc_direction'] * (single_veh_data['y'] - 0.5) >= 0),
        'time']
    end_time_candidate_2 = single_veh_data.loc[
        time_filter & (single_veh_data['time'] > crossing_time)
        & (single_veh_data['relative_vy'] == 0),
        'time']
    if end_time_candidate_1.empty and end_time_candidate_2.empty:
        return float('nan'), float('nan')
    elif end_time_candidate_1.empty and not end_time_candidate_2.empty:
        end_time = end_time_candidate_2.iloc[0]
    elif not end_time_candidate_1.empty and end_time_candidate_2.empty:
        end_time = end_time_candidate_1.iloc[0]
    else:
        end_time = np.min([end_time_candidate_1.iloc[0],
                           end_time_candidate_2.iloc[0]])

    if lc_data['time'] == end_time:
        raise RuntimeError('Lane change end time equals the start time.\n'
                           'Details: id={}, start time={}, '
                           'end_time={}'.format(lc_data['veh_id'],
                                                lc_data['time'],
                                                end_time))
    # lc_data[['crossing_time', 'end_time']] = [crossing_time, end_time]
    return crossing_time, end_time


def check_surrounding_vehicle_changes(veh_data: pd.DataFrame,
                                      lc_data: pd.Series,
                                      crossing_time: float,
                                      end_time: float) -> str:
    """ Checks if any surrounding vehicles changed during a lane
    change maneuver.

    :param veh_data: vehicle records of a single simulation
    :param lc_data: data for a single lane change
    :param crossing_time: time the vehicle crosses the lane boundary
    :param end_time: lane change end time
    :return: String describing whether there was any change
    """
    if np.isnan(end_time):
        return ''

    time_filter = ((veh_data['time'] >= lc_data['time'])
                   & (veh_data['time'] <= end_time))
    veh_filter = veh_data['veh_id'] == lc_data['veh_id']
    veh_data_lc = veh_data[veh_filter & time_filter]
    leaders_ids = veh_data_lc['leader_id'].fillna(0)
    dest_lane_follower_id = veh_data.loc[
        (veh_data['leader_id'] == lc_data['veh_id']) & time_filter
        & (veh_data['time'] > crossing_time), 'veh_id']

    note = []
    if np.any(leaders_ids[veh_data_lc['time'] < crossing_time]
              != lc_data['lo_id']):
        note.append('lo changed during LC')
    if np.any(leaders_ids[veh_data_lc['time'] > crossing_time]
              != lc_data['ld_id']):
        note.append('ld changed during LC')
    if np.any(dest_lane_follower_id != lc_data['fd_id']):
        note.append('fd changed during LC')
    return '; '.join(note)


def compute_initial_lane_change_risks(lc_data: pd.Series) -> (float, float,
                                                              float):
    """
    Computes risk, defined as the worst-case braking scenario collision
    severity, between lane changing vehicle and the three relevant
    surrounding vehicles

    :param lc_data: data for a single lane change; must contain the vehicle
     types
    :return: initial risks to leader at the origin lane, leader at the
     destination lane, and follower at the destination lane
    """
    # veh_type = veh_data.loc[veh_data['veh_id'] == lc_data['veh_id'],
    #                         'veh_type'].iloc[0]
    # veh_type = veh_data.get_group(lc_data['veh_id'])['veh_type'].iloc[0]
    veh_type = lc_data['veh_type']
    lane_changing_veh = Vehicle(veh_type)
    risk_lo, risk_ld, risk_fd = 0, 0, 0
    if lc_data['lo_id'] > 0:
        # veh_type = veh_data.loc[veh_data['veh_id'] == lc_data['lo_id'],
        #                         'veh_type'].iloc[0]
        # veh_type = veh_data.get_group(lc_data['lo_id'])['veh_type'].iloc[0]
        veh_type = lc_data['lo_type']
        orig_lane_leader = Vehicle(veh_type)
        risk_lo = compute_risk(lane_changing_veh, orig_lane_leader,
                               True, lc_data['vx'], lc_data['lo_vx'],
                               lc_data['lo_gap'])
    if lc_data['ld_id'] > 0:
        # veh_type = veh_data.loc[veh_data['veh_id'] == lc_data['ld_id'],
        #                         'veh_type'].iloc[0]
        # veh_type = veh_data.get_group(lc_data['ld_id'])['veh_type'].iloc[0]
        veh_type = lc_data['ld_type']
        dest_lane_leader = Vehicle(veh_type)
        risk_ld = compute_risk(lane_changing_veh, dest_lane_leader,
                               True, lc_data['vx'], lc_data['ld_vx'],
                               lc_data['ld_gap'])
    if lc_data['fd_id'] > 0 and lc_data['fd_vx'] > 0.5:
        # veh_type = veh_data.loc[veh_data['veh_id'] == lc_data['fd_id'],
        #                         'veh_type'].iloc[0]
        # veh_type = veh_data.get_group(lc_data['fd_id'])['veh_type'].iloc[0]
        try:
            veh_type = lc_data['fd_type']
        except KeyError:
            print('no fd type')
        dest_lane_follower = Vehicle(veh_type)
        risk_fd = compute_risk(dest_lane_follower, lane_changing_veh,
                               False, lc_data['fd_vx'],
                               lc_data['vx'], lc_data['fd_gap'])
    return risk_lo, risk_ld, risk_fd


def get_risks_during_lane_change(
        lc_veh_data: pd.DataFrame, fd_data: pd.DataFrame,
        lc_data: pd.Series, end_time: float) -> (float, float, float):
    """
    Returns the risks relative to each surrounding vehicle exclusively over
    the duration of the lane change. Note: this yields different results from
    'get_total_lane_change_risk', which returns the risks from the start of
    the lane change till the end of longitudinal adjustments.

    :param lc_veh_data: Data of the vehicle performing the lane change
    :param fd_data: Data of the follower at the destination lane
    :param lc_data: data for a single lane change
    :param end_time: lane change end time
    :return: total risks to leader at the origin lane, leader at the
     destination lane, and follower at the destination lane
    """
    # lc_veh_data = veh_data.get_group(lc_data['veh_id'])
    delta_t = round(lc_veh_data['time'].iloc[1]
                    - lc_veh_data['time'].iloc[0], 2)
    time_filter = ((lc_veh_data['time'] >= lc_data['time'])
                   & (lc_veh_data['time'] <= end_time))
    # lc_veh_data = veh_data.loc[(veh_data['veh_id'] == lc_data['veh_id'])
    #                            & time_filter]
    risk_lo, risk_ld, risk_fd = 0, 0, 0
    if lc_data['lo_id'] != 0:
        risk_lo = lc_veh_data.loc[(lc_veh_data['leader_id'] == lc_data['lo_id'])
                                  & time_filter,
                                  'risk'].sum() * delta_t
    if lc_data['ld_id'] != 0:
        risk_ld = lc_veh_data.loc[(lc_veh_data['leader_id'] == lc_data['ld_id'])
                                  & time_filter,
                                  'risk'].sum() * delta_t
    if lc_data['fd_id'] != 0:
        time_filter = ((fd_data['time'] >= lc_data['time'])
                       & (fd_data['time'] <= end_time))
        fd_data = fd_data.loc[(fd_data['leader_id'] == lc_data['veh_id'])
                              # & (veh_data['veh_id'] == lc_data['fd_id'])
                              & time_filter]
        risk_fd = fd_data['risk'].sum() * delta_t

    return risk_lo, risk_ld, risk_fd


def get_total_lane_change_risk(
        risky_maneuvers: pd.DataFrame, lc_data: pd.Series,
        end_time: float) -> (float, float, float):
    """
    Gets the risks from the start of the lane change till the end of
    longitudinal adjustments. this yields different results from
    'get_risks_during_lane_change', which returns the risks only during the
     lane change maneuver.

    :param risky_maneuvers: Data frame where each row details one risky
     maneuver
    :param lc_data: data for a single lane change
    :param end_time: lane change end time
    :return: total risks to leader at the origin lane, leader at the
     destination lane, and follower at the destination lane
    """

    # We check which "risky" maneuvers start during a lane change, and we
    # assume that total risk of that risky maneuver is the lane change's risk.
    # NOTE: not sure this is the best (most fair?) evaluation criteria

    simulation_risk_data = risky_maneuvers[risky_maneuvers['simulation_number']
                                           == lc_data['simulation_number']]
    time_filter = ((simulation_risk_data['time'] >= lc_data['time'])
                   & (simulation_risk_data['time'] <= end_time))
    risks = dict()
    risks['lo'] = simulation_risk_data.loc[
        (simulation_risk_data['veh_id'] == lc_data['veh_id'])
        & (simulation_risk_data['leader_id'] == lc_data['lo_id'])
        & time_filter,
        'total_risk']
    risks['ld'] = simulation_risk_data.loc[
        (simulation_risk_data['veh_id'] == lc_data['veh_id'])
        & (simulation_risk_data['leader_id'] == lc_data['ld_id'])
        & time_filter,
        'total_risk']
    risks['fd'] = simulation_risk_data.loc[
        (simulation_risk_data['veh_id'] == lc_data['fd_id'])
        & (simulation_risk_data['leader_id'] == lc_data['veh_id']) &
        time_filter,
        'total_risk']
    for key in risks:
        risks[key] = 0 if risks[key].empty else risks[key].sum()
    return risks['lo'], risks['ld'], risks['fd']


def label_lane_changes(scenario_name: str, veh_data: pd.DataFrame,
                       lc_data: pd.DataFrame):
    """
    Labels lane changes as mandatory or discretionary

    :param scenario_name:
    :param veh_data: vehicle records of a single simulation
    :param lc_data: lane change data for the entire simulation
    :return:
    """
    lc_direction = lc_data['dest_lane'] - lc_data['origin_lane']
    if np.any(np.abs(lc_direction) > 1):
        warnings.warn('Vehicle changing two lanes at a time?',
                      RuntimeWarning)
    data_by_veh = veh_data.groupby('veh_id')
    exit_link = data_by_veh['link'].last()

    file_handler = FileHandler(scenario_name)
    merging_link = file_handler.get_merging_links()
    off_ramp_link = file_handler.get_off_ramp_links()
    exit_per_lc = exit_link.loc[lc_data['veh_id'].to_numpy()]
    took_off_ramp_mask = exit_per_lc.isin(off_ramp_link).to_numpy()
    lc_data['mandatory'] = False

    left_mandatory_mask = ((lc_data['origin_lane'] == 1)
                           & lc_data['link'].isin(merging_link)
                           & ~took_off_ramp_mask)
    right_mandatory_mask = ((lc_direction < 0)
                            & took_off_ramp_mask)
    lc_data.loc[left_mandatory_mask | right_mandatory_mask,
                'mandatory'] = True


def compute_fd_discomfort(fd_data: pd.DataFrame,
                          lc_data: pd.Series,
                          max_braking: List[int]) -> List[float]:
    if lc_data['fd_id'] == 0:
        return [0] * len(max_braking)

    # fd_data = data_by_veh.get_group(lc_data['fd_id'])
    sampling_interval = fd_data['time'].iloc[1] - fd_data['time'].iloc[0]

    fd_discomfort = []
    fd_accel = fd_data.loc[
        (fd_data['time'] > lc_data['time'])
        & (fd_data['time'] < lc_data['time'] + 10)
        & (fd_data['leader_id'] == lc_data['veh_id']),
        'ax']
    for b in max_braking:
        strong_braking = fd_accel[fd_accel < b]
        if strong_braking.empty:
            fd_discomfort.append(0)
        else:
            fd_discomfort.append(sum(b - strong_braking.to_numpy())
                                 * sampling_interval)
    return fd_discomfort


# TODO: move methods to proper location in file
def compute_collision_free_gap(follower: Vehicle, leader: Vehicle,
                               is_lane_changing: bool,
                               follower_vel: Union[float, List[float]],
                               leader_vel: Union[float, List[float]]):
    """
    Analytically computes the minimum collision-free gap
    :param follower:
    :param leader:
    :param is_lane_changing:
    :param follower_vel:
    :param leader_vel:
    :return:
    """
    # follower_lambda1 = np.zeros(len(is_lane_changing))
    # follower_max_brake = np.zeros(len(is_lane_changing))
    if is_lane_changing:
        follower_max_brake = follower.max_brake_lane_change
        follower_lambda1 = follower.lambda1_lane_change
    else:
        follower_max_brake = follower.max_brake
        follower_lambda1 = follower.lambda1

    gamma = leader.max_brake / follower_max_brake
    gamma_threshold = leader_vel / (follower_vel + follower_lambda1)
    if gamma > gamma_threshold:
        safe_gap = (
                (follower_vel + follower_lambda1) ** 2 / 2 / follower_max_brake
                - leader_vel ** 2 / 2 / leader.max_brake + follower.lambda0
        )
    elif leader.max_brake < follower_max_brake:
        delta_vel = follower_vel - leader_vel
        delta_max_brake = follower_max_brake - leader.max_brake
        safe_gap = (
                (delta_vel + follower_lambda1) ** 2 / 2 / delta_max_brake
                + follower.lambda0
        )
    else:
        safe_gap = 0
    return safe_gap


def compute_risk(follower: Vehicle, leader: Vehicle, is_lane_changing: bool,
                 follower_vel: float, leader_vel: float, gap: float):
    """

    :param follower:
    :param leader:
    :param is_lane_changing:
    :param follower_vel:
    :param leader_vel:
    :param gap:
    :return:
    """
    # TODO: not sure we should have this
    # if follower_vel == 0:  # corner case
    #     return 0

    if is_lane_changing:
        follower_max_brake = follower.max_brake_lane_change
        follower_lambda1 = follower.lambda1_lane_change
        follower_tau_j = follower.tau_j_lane_change
    else:
        follower_max_brake = follower.max_brake
        follower_lambda1 = follower.lambda1
        follower_tau_j = follower.tau_j

    safe_gap = compute_collision_free_gap(follower, leader, is_lane_changing,
                                          follower_vel, leader_vel)
    delta_vel = -(leader_vel - follower_vel)

    thresholds = compute_gap_thresholds_for_collision(
        follower, leader, leader_vel, delta_vel, follower_max_brake,
        follower_lambda1, follower_tau_j
    )

    is_below_safe_gap = gap < safe_gap
    is_below_threshold = list()
    for i in range(len(thresholds)):
        is_below_threshold.append(gap < thresholds[i])

    idx_cases = list()
    # [0] Collision before tau_d and t_l
    idx_cases.append(is_below_safe_gap
                     & is_below_threshold[0] & is_below_threshold[1])
    # [1] Collision before tau_d and after t_l
    idx_cases.append(is_below_safe_gap
                     & is_below_threshold[0] & ~is_below_threshold[1])
    # [2] Collision before tau_d + tau_j and t_l
    idx_cases.append(is_below_safe_gap
                     & ~is_below_threshold[0] & is_below_threshold[2]
                     & is_below_threshold[3])
    # [3] Collision before tau_d + tau_j and after t_l
    idx_cases.append(is_below_safe_gap &
                     ~is_below_threshold[0] & is_below_threshold[2]
                     & ~is_below_threshold[3])
    # [4] Collision before t_E and t_l
    idx_cases.append(is_below_safe_gap &
                     ~is_below_threshold[2] & is_below_threshold[4])
    # [5] Collision before t_E and after t_l
    idx_cases.append(is_below_safe_gap &
                     ~is_below_threshold[2] & ~is_below_threshold[4])
    # [6] No collision
    idx_cases.append(True)  # this is only selected if none of the other
    # entries is true

    risk = compute_risk_given_phase(
        follower, leader, np.array([follower_vel]), np.array([leader_vel]),
        np.array([delta_vel]), np.array([gap]), np.array([follower_max_brake]),
        np.array([follower_lambda1]), np.argmax(idx_cases))
    # for case in range(len(idx_cases)):
    #     mask = idx_cases[case]
    #     risk[mask] = compute_risk_given_phase(
    #         follower, leader, follower_vel[mask], leader_vel[mask],
    #         delta_vel[mask], gap[mask], follower_max_brake[mask],
    #         follower_lambda1[mask], follower_tau_j[mask], case)

    return risk[0]


def compute_gap_thresholds_for_collision(follower: Vehicle, leader: Vehicle,
                                         leader_vel, delta_vel,
                                         follower_max_brake,
                                         follower_lambda1, follower_tau_j):
    """
    Computes the different gap thresholds that help determine during which
    phase of the worst-case braking scenario collision happens and returns

    :param follower:
    :param leader:
    :param leader_vel:
    :param delta_vel:
    :param follower_max_brake:
    :param follower_lambda1:
    :param follower_tau_j:
    :return:
    """
    # TODO: we don't need to compute all thresholds. We can eliminate some
    #     based on the leader stopping time

    leader_stopping_time = leader_vel / leader.max_brake
    # Gap thresholds
    # (note that delta_vel is follower_vel - leader_vel)
    thresholds = list()
    # is_below_safe_gap = gap < safe_gap
    # [0] Collision before tau_d
    thresholds.append(
        follower.brake_delay
        * ((follower.accel_t0 + leader.max_brake) / 2
           * follower.brake_delay
           + delta_vel)
    )
    # [1] Collision before t_l when t_l < tau_d
    thresholds.append(
        leader_stopping_time
        * ((follower.accel_t0 + leader.max_brake) / 2
           * leader_stopping_time
           + delta_vel)
    )
    # [2] Collision before tau_d + tau_j
    thresholds.append(
        (follower.brake_delay + follower_tau_j)
        * ((follower.accel_t0 + leader.max_brake) / 2
           * (follower.brake_delay + follower_tau_j)
           + delta_vel)
        - follower.max_jerk * follower_tau_j ** 3 / 6
    )
    # [3] Collision before t_l when tau_d < t_l < tau_d + tau_j
    thresholds.append(
        leader_stopping_time
        * ((follower.accel_t0 + leader.max_brake) / 2
           * leader_stopping_time
           + delta_vel)
        - follower.max_jerk
        * (leader_stopping_time - follower.brake_delay) ** 3 / 6
    )
    thresholds.append(
        leader_stopping_time
        * ((leader.max_brake - follower_max_brake) / 2
           * leader_stopping_time
           + delta_vel + follower_lambda1)
        + follower.lambda0
    )
    return thresholds


def compute_risk_given_phase(follower: Vehicle, leader: Vehicle,
                             follower_vel, leader_vel, delta_vel, gap,
                             follower_max_brake, follower_lambda1,
                             case):
    """

    :param follower:
    :param leader:
    :param follower_vel:
    :param leader_vel:
    :param delta_vel:
    :param gap:
    :param follower_max_brake:
    :param follower_lambda1:
    :param case:
    :return:
    """
    if case == 0:
        risk_squared = (delta_vel ** 2
                        + 2 * gap * (follower.accel_t0 + leader.max_brake))
        risk = np.sqrt(risk_squared)
    elif case == 1:
        risk_squared = (follower_vel ** 2
                        + follower.accel_t0
                        * (2 * gap + leader_vel ** 2 / leader.max_brake))
        risk = np.sqrt(risk_squared)
    elif case == 2:
        risk = SSMEstimator._compute_risk_during_jerk_phase(
            follower, leader, gap, follower_vel, leader_vel,
            False
        )
    elif case == 3:
        risk = SSMEstimator._compute_risk_during_jerk_phase(
            follower, leader, gap, follower_vel, leader_vel,
            True
        )
    elif case == 4:
        risk_squared = ((-delta_vel - follower_lambda1) ** 2
                        + 2 * (leader.max_brake - follower_max_brake)
                        * (gap - follower.lambda0))
        risk = np.sqrt(risk_squared)
    elif case == 5:
        risk_squared = ((follower_vel + follower_lambda1) ** 2
                        - 2 * follower_max_brake
                        * (gap + leader_vel ** 2 / 2 / leader.max_brake
                           - follower.lambda0))
        risk = np.sqrt(risk_squared)
    else:
        risk = np.zeros(len(follower_vel))

    return risk


def extract_lane_change_data_from_ngim(data: pd.DataFrame):
    # idx_of_quick_lc = lc_data[(lc_data['veh_id'].diff()==0)
    # & (lc_data['time'].diff() <= 5)]
    pass


def identify_ngsim_lane_changes(data: pd.DataFrame):
    """
    Finds the index of all lane changes in the data
    :param data: vehicle trajectory dataframe
    :return: (indices indicating one time sample before the lane id changes)
    """
    if data['time'].loc[0] > 0:  # during tests, we don't want to repeat this
        # at every call of the function
        data['time'] -= data['time'].loc[0]  # make it start at zero
        data['time'] /= 1000  # to seconds

    data['future_lane'] = data['lane'].shift(-1, fill_value=0).astype(int)
    veh_change_indicator = data['veh_id'].diff(-1) != 0
    data.loc[veh_change_indicator, 'future_lane'] = data.loc[
        veh_change_indicator, 'lane']
    # Remove cases when vehicle goes from on-ramp to auxiliary lane or from
    # auxiliary lane to off-ramp (they're all the same lane)
    data.loc[(data['lane'] == 7) & (data['future_lane'] == 6),
             'future_lane'] = 7
    data.loc[(data['lane'] == 6) & (data['future_lane'] == 8),
             'future_lane'] = 6
    data['lane_change'] = data['future_lane'] - data['lane']

    # All instances when a vehicle's lane id changes.
    # lane_change > 0: left
    # lane_change < 0: right
    # lane_change = -data['lane'].diff(-1)  # following row - current row
    # lane_change[data['veh_id'].diff(-1) != 0] = 0
    # lane_change_idx = data[(lane_diff != 0)
    #                        & (data['veh_id'].diff(-1) == 0)].index

    # Remove cases when vehicle goes from on-ramp to auxiliary lane or from
    # auxiliary lane to off-ramp (they're all the same lane)
    # lane_change[find_lane_change_from_to(data, lane_change, 7, 6)] = 0
    # lane_change[find_lane_change_from_to(data, lane_change, 6, 8)] = 0

    # Remove consecutive lane changes in short time intervals
    time_threshold = 5
    lane_change_data = data.loc[data['lane_change'] != 0].copy()
    # Indices of lane changes that happen right after another
    drop_idx_1 = lane_change_data.loc[
        (lane_change_data['time'].diff() < time_threshold)
        & (lane_change_data['veh_id'].diff() == 0)].index
    # Indices of lane changes that happen right before another
    drop_idx_2 = lane_change_data.loc[
        (-lane_change_data['time'].diff(-1) < time_threshold)
        & (lane_change_data['veh_id'].diff(-1) == 0)].index
    # drop_idx_2 = drop_idx_1 - 1  # only works if we reset the index
    lane_change_data.drop(drop_idx_1.union(drop_idx_2), inplace=True)
    find_ngsim_lane_change_start(data, lane_change_data.index)

    return lane_change_data


def find_ngsim_lane_change_start(data: pd.DataFrame,
                                 lane_change_idx: pd.Index):
    """
    Given trajectories and indices of where the vehicles cross lanes,
    estimate when the lane change maneuver started
    :param data:
    :param lane_change_idx:
    :return:
    """
    sampling_time = 0.1
    window_seconds = 1
    window_samples = int(window_seconds / sampling_time)
    data['vy'] = data['y'].diff() / sampling_time
    data.loc[data['veh_id'].diff() != 0, 'vy'] = 0
    data['vy_ma'] = data['vy'].rolling(window_samples, center=True).mean()
    speed_threshold = 0.2

    # We expect no more than 1000 lane changes per NGSIM file so we can
    # iterate over them.
    n_seconds = 5
    n_samples = n_seconds / sampling_time
    df_list = []
    veh_ids = data['veh_id']
    counter = 0
    for i in lane_change_idx:
        if (veh_ids[i] != veh_ids[i - n_samples - window_samples // 2]
                or veh_ids[i] != veh_ids[i + n_samples + window_samples // 2]):
            continue
        lc_direction = 2 * (data.loc[i, 'lane_change'] > 0) - 1
        t_center = data.loc[i, 'time']
        times = data.loc[i - n_samples: i + n_samples, 'time'] - t_center
        vy = lc_direction * data.loc[i - n_samples:i + n_samples, 'vy']
        vy_ma = lc_direction * data.loc[i - n_samples:i + n_samples, 'vy_ma']
        df_list.append(pd.DataFrame({'time': times, 'vy': vy, 'vy_ma': vy_ma}))
        df_list[-1]['veh_id'] = data.loc[i, 'veh_id']
        df_list[-1]['lc_number'] = counter
        df_list[-1]['lc_direction'] = 'right' if lc_direction > 0 else 'left'
        counter += 1
        # data_before_lc = (lc_direction * data.loc[i - n_samples:i - 1, 'vy_ma']
        #                   > speed_threshold).argmax()
        # data_after_lc = (lc_direction * data.loc[i + 1: i + n_samples, 'vy_ma']
        #                  < speed_threshold).argmax()
    vy_df = pd.concat(df_list)
    return vy_df


# def find_lane_change_from_to(data: pd.DataFrame,
#                              lane_changes: pd.Series,
#                              origin_lane: int, destination_lane: int):
#     """
#     Find the indices of lane changes from origin lane to destination lane
#
#     :param data: vehicle trajectories
#     :param lane_changes: series where non-zero values indicate that the
#      vehicle crosses the lane line in the next time step
#     :param origin_lane: index of the origin lane
#     :param destination_lane: index of the destination lane
#     """
#     lane_change_idx = lane_changes[lane_changes != 0].index
#     lc_from_origin_lane = data.loc[lane_change_idx].loc[data['lane']
#                                                         == origin_lane]
#     # Among lane changes that start at the origin lane, get the ones which
#     # end at the destination lane.
#     return data.loc[lc_from_origin_lane.index + 1].loc[
#                data['lane'] == destination_lane].index - 1


# ================================ Classes =================================== #
class SSMEstimator:
    coded_ssms = {'TTC', 'DRAC', 'CPI', 'collision_free_gap', 'DTSG', 'vf_gap',
                  'risk', 'estimated_risk', 'barrier_function_safe_gap'}
    ttc_threshold = 1.5  # [s]
    drac_threshold = 3.5  # [m/s2]

    def __init__(self, veh_data):
        self.veh_data = veh_data

    def include_ssms(self, ssm_names: List[str]):
        for ssm in ssm_names:
            self.include_ssm_by_name(ssm)

    def include_ssm_by_name(self, ssm_name: str):
        ssm_name = ssm_name.lower()
        if 'ttc' in ssm_name:
            self.include_ttc()
        elif 'drac' in ssm_name:
            self.include_drac()
        elif ssm_name == 'risk':
            self.include_collision_free_gap()
            self.include_risk()
        elif ssm_name == 'risk_no_lane_change':
            self.include_collision_free_gap(consider_lane_change=False)
            self.include_risk(consider_lane_change=False)
        elif ssm_name == 'barrier_function_risk':
            self.include_barrier_function_risk()
        else:
            raise ValueError('ssm ', ssm_name, ' cannot be called by the '
                                               'include_ssm_by_name method')

    def include_ttc(self, safe_threshold: float = ttc_threshold):
        """
        Includes Time To Collision (TTC) and a flag indicating if the TTC is
        below a threshold to the the dataframe.
        TTC = deltaX/deltaV if follower is faster; otherwise infinity

        :param safe_threshold: [Optional] Threshold against which TTC values
         are compared.
        :return: None
        """
        veh_data = self.veh_data
        veh_data['TTC'] = float('nan')
        valid_ttc_idx = veh_data['delta_v'] > 0
        ttc = (veh_data['delta_x'].loc[valid_ttc_idx]
               / veh_data['delta_v'].loc[valid_ttc_idx])
        veh_data.loc[valid_ttc_idx, 'TTC'] = ttc
        veh_data['low_TTC'] = veh_data['TTC'] < safe_threshold

    def include_drac(self, safe_threshold: float = drac_threshold):
        """
        Includes Deceleration Rate to Avoid Collision (DRAC) and a flag
        indicating if the DRAC is above a threshold to the dataframe.
        DRAC = deltaV^2/(2.deltaX), if follower is faster; otherwise zero

        :param safe_threshold: [Optional] Threshold against which DRAC values
         are compared.
        :return: None
        """
        veh_data = self.veh_data
        veh_data['DRAC'] = 0
        valid_drac_idx = veh_data['delta_v'] > 0
        drac = (veh_data['delta_v'].loc[valid_drac_idx] ** 2
                / 2 / veh_data['delta_x'].loc[valid_drac_idx])
        veh_data.loc[valid_drac_idx, 'DRAC'] = drac
        veh_data['high_DRAC'] = veh_data['DRAC'] > safe_threshold

    def include_cpi(self, max_decel_data, is_default_vissim=True):
        """
        Includes Crash Probability Index (CPI) to the dataframe

        CPI = Prob(DRAC > MADR), where MADR is the maximum available
        deceleration rate. Formally, we should check the truncated Gaussian
        parameters for each velocity. However, the default VISSIM max
        decel is a linear function of the velocity and the other three
        parameters are constant. We make use of this to speed up this
        function.

        :param max_decel_data: dataframe with maximum deceleration per
        vehicle type per speed
        :param is_default_vissim: boolean to identify if data was generated
        using default VISSIM deceleration parameters
        :return: None
        """

        veh_types = np.unique(
            max_decel_data.index.get_level_values('veh_type'))
        df = self.veh_data
        if 'DRAC' not in df.columns:
            self.include_drac()
        df['CPI'] = 0
        # veh_types = np.unique(df['veh type'])
        for veh_type in veh_types:
            idx = (df['veh_type'] == veh_type) & (df['DRAC'] > 0)
            if is_default_vissim:
                first_row = max_decel_data.loc[veh_type, 0]
                possible_vel = max_decel_data.loc[veh_type].index
                min_vel = 0
                max_vel = max(possible_vel)
                decel_min_vel = max_decel_data.loc[veh_type, min_vel]['mean']
                decel_max_vel = max_decel_data.loc[veh_type, max_vel]['mean']
                madr_array = (decel_min_vel + (decel_max_vel - decel_min_vel)
                              / max_vel * df.loc[idx, 'vx'])
                df.loc[idx, 'CPI'] = truncnorm.cdf(df.loc[idx, 'DRAC'],
                                                   a=first_row['norm_min'],
                                                   b=first_row['norm_max'],
                                                   loc=(-1) * madr_array,
                                                   scale=first_row['std'])
            else:
                a_array = []
                b_array = []
                madr_array = []
                std_array = []
                for vel in df.loc[idx, 'vx']:
                    row = max_decel_data.loc[veh_type, round(vel, -1)]
                    a_array.append(row['norm_min'])
                    b_array.append(row['norm_max'])
                    madr_array.append(-1 * row['mean'])
                    std_array.append(row['std'])
                df.loc[idx, 'CPI'] = truncnorm.cdf(df.loc[idx, 'DRAC'],
                                                   a=a_array, b=b_array,
                                                   loc=madr_array,
                                                   scale=std_array)

    def include_collision_free_gap(self, same_type_gamma=1,
                                   consider_lane_change: bool = True):
        """
        Computes the collision free (safe) gap and adds it to the dataframe.
        If the vehicle violates the safe gap, the absolute value of the
        distance to the safe gap (DTSG) is also added to the dataframe. The
        DTSG column is padded with zeros.
        :param same_type_gamma: factor multiplying standard value of maximum
         braking of the leader when both leader and follower are of the same
         type. Values greater than 1 indicate more conservative assumptions
        :param consider_lane_change: if set to false, we don't consider the
         effects of lane change, i.e., we treat all situations as simple
         vehicle following. If set to true, we overestimate the risk by
         assuming a reduced max brake during lane changes.
        """

        ssm_1 = 'safe_gap'
        ssm_2 = 'DTSG'
        self.include_distance_based_ssm(
            ssm_1, same_type_gamma, consider_lane_change=consider_lane_change)

        if not consider_lane_change:
            ssm_1 += '_no_lane_change'
            ssm_2 += '_no_lane_change'
        self.veh_data[ssm_2] = self.veh_data['delta_x'] - self.veh_data[ssm_1]
        self.veh_data.loc[self.veh_data[ssm_2] > 0, ssm_2] = 0
        self.veh_data[ssm_2] = np.abs(self.veh_data[ssm_2])

    def include_vehicle_following_gap(self, same_type_gamma=1, rho=0.2,
                                      free_flow_velocity=None):
        """
        Includes time headway based desired vehicle following gap to the
        dataframe
        The vehicle following gap is an overestimation of the collision free
        gap which assumes:
        . (1-rho)vE(t) <= vL(t) <= vE(t), for all t
        . vE(t) <= Vf, for all t.

        :param same_type_gamma: factor multiplying standard value of maximum
         braking of the leader when both leader and follower are of the same
         type. Values greater than 1 indicate more conservative assumptions
        :param rho: defines the lower bound on the leader velocity following
         (1-rho)vE(t) <= vL(t). Must be in the interval [0, 1]
        :param free_flow_velocity: (optional) must be given in m/s
        :return:
        """
        self.include_distance_based_ssm('vf_gap', same_type_gamma, rho,
                                        free_flow_velocity)

    def include_risk(self, same_type_gamma: float = 1,
                     consider_lane_change: bool = True):
        """
        Includes exact risk, computed as the relative velocity at
        collision time under the worst case scenario, to the dataframe

        :param consider_lane_change: if set to false, we don't consider the
         effects of lane change, i.e., we treat all situations as simple
         vehicle following. If set to true, we overestimate the risk by
         assuming a reduced max brake during lane changes.
        :param same_type_gamma: factor multiplying standard value of maximum
         braking of the leader when both leader and follower are of the same
         type. Values greater than 1 indicate more conservative assumptions
        """
        self.include_distance_based_ssm(
            'risk', same_type_gamma,
            consider_lane_change=consider_lane_change)

    def include_estimated_risk(self, same_type_gamma=1, rho=0.2,
                               free_flow_velocity=None):
        """
        Includes estimated risk, which is an overestimation of the exact risk
        under certain assumptions, to the dataframe
        Assumptions:
        . (1-rho)vE(t) <= vL(t) <= vE(t), for all t
        . vE(t) <= Vf, for all t.

        :param same_type_gamma: factor multiplying standard value of maximum
         braking of the leader when both leader and follower are of the same
         type. Values greater than 1 indicate more conservative assumptions
        :param rho: defines the lower bound on the leader velocity following
         (1-rho)vE(t) <= vL(t). Must be in the interval [0, 1]
        :param free_flow_velocity: (optional) must be given in m/s
        :return:
        """
        self.include_distance_based_ssm('estimated_risk', same_type_gamma, rho,
                                        free_flow_velocity)

    def include_barrier_function_risk(self):
        """
        Computes the safe gap as defined by the control barrier function and
        compares it to the current gap. We only include values if they are
        negative.
        :return: nothing; the method changes the dataframe.
        """
        time_headway = 1
        standstill_distance = 3
        comfortable_braking = 4

        gap = self.veh_data['delta_x'].to_numpy()
        follower_vel = self.veh_data['vx'].to_numpy()
        delta_vel = self.veh_data['delta_v'].to_numpy()
        leader_vel = follower_vel - delta_vel
        safe_gap = (time_headway * follower_vel + standstill_distance
                    + (follower_vel ** 2 - leader_vel ** 2)
                    / 2 / comfortable_braking)
        diff_to_safe_gap = safe_gap - gap
        self.veh_data['barrier_function_risk'] = diff_to_safe_gap
        self.veh_data.loc[diff_to_safe_gap < 0, 'barrier_function_risk'] = 0
        # no leader cases
        self.veh_data.loc[self.veh_data['veh_id'] == self.veh_data['leader_id'],
                          'barrier_function_risk'] = 0

    def include_distance_based_ssm(self, ssm_name: str,
                                   same_type_gamma: float = 1,
                                   rho: float = 0.2,
                                   free_flow_velocity: float = None,
                                   consider_lane_change: bool = True):
        """
        Generic method to include one out of a set of distance based surrogate
        safety measures.
        :param ssm_name: {collision_free_gap, vf_gap, risk, estimated_risk}
        :param same_type_gamma: factor multiplying standard value of maximum
         braking of the leader when both leader and follower are of the same
         type. Values greater than 1 indicate more conservative assumptions
        :param rho: defines the lower bound on the leader velocity following
         (1-rho)vE(t) <= vL(t). Must be in the interval [0, 1]
        :param consider_lane_change: if set to false, we don't consider the
         effects of lane change, i.e., we treat all situations as simple
         vehicle following. If set to true, we overestimate the risk by
         assuming a reduced max brake during lane changes.
        :param free_flow_velocity: (optional) must be given in m/s
        """
        veh_types = np.unique(self.veh_data[['veh_type', 'leader_type']])
        df = self.veh_data
        has_leader = df['veh_id'] != df['leader_id']
        if not consider_lane_change:
            ssm_name += "_no_lane_change"
        df[ssm_name] = 0

        for follower_type in veh_types:
            try:
                follower = Vehicle(follower_type, gamma=1)
            except KeyError:
                print('Follower of type {} not found. Skipping it.'.
                      format(follower_type))
                continue
            if not follower.is_relevant:
                print('Skipping follower of type ', follower.type)
                continue

            if free_flow_velocity is not None:
                follower.free_flow_velocity = free_flow_velocity
            follower_idx = (df['veh_type'] == follower_type) & has_leader

            for leader_type in veh_types:
                try:
                    if follower_type == leader_type:
                        gamma = same_type_gamma
                    else:
                        gamma = 1
                    leader = Vehicle(leader_type, gamma=gamma)
                except KeyError:
                    print('Leader of type {} not found. Skipping it.'.
                          format(leader_type))
                    continue
                if not leader.is_relevant:
                    print('Skipping leader of type ', leader.type)
                    continue

                veh_idx = follower_idx & (df['leader_type'] == leader_type)
                if ssm_name.startswith('safe_gap'):
                    df.loc[veh_idx, ssm_name] = (
                        self._compute_collision_free_gap(
                            veh_idx, follower, leader, consider_lane_change))
                elif ssm_name.startswith('vf_gap'):
                    df.loc[veh_idx, ssm_name] = (
                        self._compute_vehicle_following_gap(
                            veh_idx, follower, leader, rho))
                elif ssm_name.startswith('risk'):
                    df.loc[veh_idx, ssm_name] = self._compute_risk(
                        veh_idx, follower, leader, consider_lane_change)
                elif ssm_name.startswith('estimated_risk'):
                    df.loc[veh_idx, ssm_name] = (
                        self._compute_estimated_risk(veh_idx, follower,
                                                     leader, rho))
                else:
                    print('Unknown distance based SSM requested. Skipping...')
                    pass

    def _compute_collision_free_gap(self, veh_idx: pd.Series,
                                    follower: Vehicle, leader: Vehicle,
                                    consider_lane_change: bool = False):
        """
        The collision free is computed such that, under the worst case
        braking scenario, both vehicles achieve full stop without colliding

        :param veh_idx: boolean array indicating which vehicles of the
         dataset are being considered
        :param follower: following vehicle - object of the Vehicle class
        :param leader: leading vehicle - object of the Vehicle class
        :param consider_lane_change: if set to false, we don't consider the
         effects of lane change, i.e., we treat all situations as simple
         vehicle following. If set to true, we overestimate the risk by
         assuming a reduced max brake during lane changes.
        :return: safe gaps
        """
        # TODO: can't we call the function compute_collision_free_gap from
        #  here instead of repeating most of the code?
        follower_vel = self.veh_data.loc[veh_idx, 'vx'].to_numpy()
        delta_vel = self.veh_data.loc[veh_idx, 'delta_v'].to_numpy()
        leader_vel = follower_vel - delta_vel
        safe_gap = np.zeros(len(follower_vel))

        (follower_effective_max_brake,
         follower_effective_lambda1, _) = (
            self.get_braking_parameters_over_time(
                self.veh_data.loc[veh_idx],
                follower,
                consider_lane_change)
        )

        gamma = leader.max_brake / follower_effective_max_brake
        gamma_threshold = leader_vel / (follower_vel
                                        + follower_effective_lambda1)
        is_above = gamma >= gamma_threshold

        safe_gap[is_above] = (
            (follower_vel[is_above] ** 2 /
             (2 * follower_effective_max_brake[is_above])
             - leader_vel[is_above] ** 2 / (2 * leader.max_brake)
             + (follower_effective_lambda1[is_above] * follower_vel[is_above]
                / follower_effective_max_brake[is_above])
             + follower_effective_lambda1[is_above] ** 2 /
             (2 * follower_effective_max_brake[is_above])
             + follower.lambda0)
        )
        if any(gamma < 1):
            is_below = ~is_above
            brake_difference = (follower_effective_max_brake[is_below] -
                                leader.max_brake)
            safe_gap[is_below] = (
                (delta_vel[is_below] ** 2 / 2 / brake_difference
                 + (follower_effective_lambda1[is_below] * delta_vel[is_below]
                    / brake_difference)
                 + follower_effective_lambda1[is_below] ** 2
                 / 2 / brake_difference + follower.lambda0)
            )
        return safe_gap

    def _compute_vehicle_following_gap(self, veh_idx: pd.Series,
                                       follower: Vehicle, leader: Vehicle,
                                       rho: float = 0.2):
        """
        Computes time headway based vehicle following gap

        The vehicle following gap is an overestimation of the collision free
        gap which assumes:
        . (1-rho)vE(t) <= vL(t) <= vE(t), for all t
        . vE(t) <= Vf, for all t.

        :param veh_idx: boolean array indicating which vehicles of the
         dataset are being considered
        :param follower: following vehicle - object of the Vehicle class
        :param leader: leading vehicle - object of the Vehicle class
        :param rho: defines the lower bound on the leader velocity following
         (1-rho)vE(t) <= vL(t). Must be in the interval [0, 1]
        :return: vehicle following gaps
        """""
        h, d = follower.compute_vehicle_following_parameters(
            leader.max_brake, rho)
        return h * self.veh_data.loc[veh_idx, 'vx'] + d

    # TODO: deprecated. Delete once we run tests with VISSIM data
    def _compute_risk_old(self, veh_idx: pd.Series,
                          follower: Vehicle, leader: Vehicle,
                          consider_lane_change: bool = True):
        """
        Computes the exact risk, which is the relative velocity at collision
        time under the worst case braking scenario

        :param veh_idx: boolean array indicating which vehicles of the
         dataset are being considered
        :param follower: following vehicle - object of the Vehicle class
        :param leader: leading vehicle - object of the Vehicle class
        :param consider_lane_change: if set to false, we don't consider the
         effects of lane change, i.e., we treat all situations as simple
         vehicle following. If set to true, we overestimate the risk by
         assuming a reduced max brake during lane changes.
        :return: exact risks
        """
        gap = self.veh_data.loc[veh_idx, 'delta_x'].to_numpy()
        follower_vel = self.veh_data.loc[veh_idx, 'vx'].to_numpy()
        delta_vel = self.veh_data.loc[veh_idx, 'delta_v'].to_numpy()
        leader_vel = follower_vel - delta_vel
        risk_squared = np.zeros(len(follower_vel))
        safe_gap_col_name = 'safe_gap'
        if not consider_lane_change:
            safe_gap_col_name += '_no_lane_change'
        safe_gap = self.veh_data.loc[veh_idx, safe_gap_col_name].to_numpy()

        (follower_effective_max_brake,
         follower_effective_lambda1,
         follower_effective_tau_j) = (
            self.get_braking_parameters_over_time(
                self.veh_data.loc[veh_idx],
                follower,
                consider_lane_change))

        gamma = leader.max_brake / follower_effective_max_brake
        gamma_threshold = leader_vel / (follower_vel +
                                        follower_effective_lambda1)
        is_gamma_above = gamma >= gamma_threshold

        # Gap thresholds
        # (note that delta_vel is follower_vel - leader_vel)
        gap_thresholds = [0] * 3
        gap_thresholds[0] = (
                follower.brake_delay
                * (follower.brake_delay / 2 * (follower.accel_t0
                                               + leader.max_brake)
                   + delta_vel))
        # For when the leader is at low speeds
        leader_low_vel_idx = (leader_vel
                              < follower.brake_delay * leader.max_brake)
        gap_thresholds[0][leader_low_vel_idx] = (
                follower.brake_delay
                * (follower.brake_delay / 2 * follower.accel_t0
                   + follower_vel[leader_low_vel_idx])
                - leader_vel[leader_low_vel_idx] ** 2 / 2 / leader.max_brake
        )
        gap_thresholds[1] = (
                (follower.brake_delay + follower_effective_tau_j)
                * (follower_effective_lambda1 + delta_vel
                   - (follower.brake_delay + follower_effective_tau_j) / 2
                   * (follower_effective_max_brake - leader.max_brake))
                + follower.lambda0)
        gap_thresholds[2] = (
                leader_vel / leader.max_brake
                * (follower_effective_lambda1 + follower_vel
                   - (follower_effective_max_brake / leader.max_brake + 1)
                   * leader_vel / 2)
                + follower.lambda0)

        idx_case_1 = gap <= gap_thresholds[0]
        idx_case_2 = ((gap > gap_thresholds[0])
                      & (gap <= gap_thresholds[1]))
        idx_case_3 = ((gap > gap_thresholds[1])
                      & ((is_gamma_above
                          & (gap <= gap_thresholds[2]))
                         | (~is_gamma_above
                            & (gap <= safe_gap))))
        idx_case_4 = (is_gamma_above
                      & (gap > gap_thresholds[2])
                      & (gap <= safe_gap))

        risk_squared[idx_case_1] = (
                delta_vel[idx_case_1] ** 2
                + 2 * gap[idx_case_1] * (follower.accel_t0
                                         + leader.max_brake)
        )
        risk_squared[idx_case_2] = 0
        # In the code, delta_v = v_f - v_l (in the written documents it's
        # usually v_l - v_f)
        risk_squared[idx_case_3] = (
                (-delta_vel[idx_case_3]
                 - follower_effective_lambda1[idx_case_3]) ** 2
                - 2 * (follower_effective_max_brake[idx_case_3]
                       - leader.max_brake)
                * (gap[idx_case_3] - follower.lambda0)
        )
        risk_squared[idx_case_4] = (
                (follower_vel[idx_case_4]
                 + follower_effective_lambda1[idx_case_4]) ** 2
                - 2 * follower_effective_max_brake[idx_case_4] *
                (gap[idx_case_4] - follower.lambda0
                 + leader_vel[idx_case_4] ** 2 / 2 / leader.max_brake)
        )
        # Couple of sanity checks
        if any(idx_case_2):
            print('Collisions during jerk phase:', np.count_nonzero(idx_case_2))
            print('I guess it''s time to code severity for this case...')
        idx_issue = risk_squared < 0
        if np.any(idx_issue):
            print('{} negative risk samples'.format(np.count_nonzero(
                idx_issue)))
            risk_squared[idx_issue] = 0

        return np.sqrt(risk_squared)

    def _compute_risk(self, veh_idx: pd.Series,
                      follower: Vehicle, leader: Vehicle,
                      consider_lane_change: bool = True):
        # TODO: create smaller functions to make this one more readable.
        gap = self.veh_data.loc[veh_idx, 'delta_x'].to_numpy()
        follower_vel = self.veh_data.loc[veh_idx, 'vx'].to_numpy()
        delta_vel = self.veh_data.loc[veh_idx, 'delta_v'].to_numpy()
        leader_vel = follower_vel - delta_vel
        risk = np.zeros(len(follower_vel))
        safe_gap_col_name = 'safe_gap'
        if not consider_lane_change:
            safe_gap_col_name += '_no_lane_change'
        safe_gap = self.veh_data.loc[veh_idx, safe_gap_col_name].to_numpy()

        (follower_max_brake,
         follower_lambda1,
         follower_tau_j) = (
            self.get_braking_parameters_over_time(
                self.veh_data.loc[veh_idx],
                follower,
                consider_lane_change))

        # Gap thresholds
        # (note that delta_vel is follower_vel - leader_vel)
        thresholds = compute_gap_thresholds_for_collision(
            follower, leader, leader_vel, delta_vel, follower_max_brake,
            follower_lambda1, follower_tau_j
        )

        is_below_safe_gap = gap < safe_gap
        is_below_threshold = list()
        for i in range(len(thresholds)):
            is_below_threshold.append(gap < thresholds[i])

        idx_cases = list()
        # [0] Collision before tau_d and t_l
        idx_cases.append(is_below_safe_gap
                         & is_below_threshold[0] & is_below_threshold[1])
        # [1] Collision before tau_d and after t_l
        idx_cases.append(is_below_safe_gap
                         & is_below_threshold[0] & ~is_below_threshold[1])
        # [2] Collision before tau_d + tau_j and t_l
        idx_cases.append(is_below_safe_gap
                         & ~is_below_threshold[0] & is_below_threshold[2]
                         & is_below_threshold[3])
        # [3] Collision before tau_d + tau_j and after t_l
        idx_cases.append(is_below_safe_gap &
                         ~is_below_threshold[0] & is_below_threshold[2]
                         & ~is_below_threshold[3])
        # [4] Collision before t_E and t_l
        idx_cases.append(is_below_safe_gap &
                         ~is_below_threshold[2] & is_below_threshold[4])
        # [5] Collision before t_E and after t_l
        idx_cases.append(is_below_safe_gap &
                         ~is_below_threshold[2] & ~is_below_threshold[4])

        for case in range(len(idx_cases)):
            mask = idx_cases[case]
            if any(mask):
                risk[mask] = compute_risk_given_phase(
                    follower, leader, follower_vel[mask], leader_vel[mask],
                    delta_vel[mask], gap[mask], follower_max_brake[mask],
                    follower_lambda1[mask], case)

        # Sanity check
        # idx_issue = risk_squared < 0
        # if np.any(idx_issue):
        #     print('{} negative risk samples'.format(np.count_nonzero(
        #         idx_issue)))
        #     risk_squared[idx_issue] = 0
        # risk = np.sqrt(risk_squared)

        if any(idx_cases[2]) or any(idx_cases[3]):
            print('Collisions during jerk phase:',
                  np.count_nonzero(idx_cases[2])
                  + np.count_nonzero(idx_cases[3]))

        return risk

    @staticmethod
    def _compute_risk_during_jerk_phase(follower: Vehicle, leader: Vehicle,
                                        gap: np.ndarray,
                                        follower_vel: np.ndarray,
                                        leader_vel: np.ndarray,
                                        leader_at_full_stop: bool):

        a = follower.max_jerk / 6
        b = -(follower.accel_t0 + follower.max_jerk * follower.brake_delay) / 2
        c = follower.max_jerk * follower.brake_delay ** 2 / 2 - follower_vel
        d = gap - follower.max_jerk * follower.brake_delay ** 3 / 6

        init_vel = follower_vel
        init_accel = follower.accel_t0

        if leader_at_full_stop:
            d += leader_vel ** 2 / 2 / leader.max_brake
            # b -= leader.max_brake / 2
            # c += leader_vel
        else:
            b -= leader.max_brake / 2
            c += leader_vel
            init_vel -= leader_vel
            init_accel += leader.max_brake

        risk = np.zeros(len(follower_vel))
        error_count = 0
        for i in range(len(follower_vel)):
            tc = np.roots([a, b, c[i], d[i]])
            tc = tc[np.isreal(tc)]
            try:
                # We could check if tc < tau_d + tau_j, but numerical
                # computations are not always exact and we end up missing
                # some cases
                tc = min(tc[tc > follower.brake_delay])
                risk[i] = (init_vel[i] + init_accel * tc
                           - follower.max_jerk * (
                                   tc - follower.brake_delay) ** 2 / 2)
            except ValueError:
                error_count += 1
        if error_count > 0:
            print("Leader at full stop: ", leader_at_full_stop)
            print("Could not find collision time in ", error_count, " cases.")
        return risk

    def _compute_estimated_risk(self, veh_idx: pd.Series,
                                follower: Vehicle, leader: Vehicle,
                                rho: float = 0.2):
        """
        Compute estimated risk, which is an overestimation of the exact risk
        under the following assumptions.
        . (1-rho)vE(t) <= vL(t) <= vE(t), for all t
        . vE(t) <= Vf, for all t.

        :param veh_idx: boolean array indicating which vehicles of the
         dataset are being considered
        :param follower: following vehicle - object of the Vehicle class
        :param leader: leading vehicle - object of the Vehicle class
        :param rho: defines the lower bound on the leader velocity following
         (1-rho)vE(t) <= vL(t). Must be in the interval [0, 1]
        :return: estimated risks
        """
        gamma = leader.max_brake / follower.max_brake
        gamma_threshold = ((1 - rho) * follower.free_flow_velocity
                           / (follower.free_flow_velocity + follower.lambda1))
        gap = self.veh_data.loc[veh_idx, 'delta_x'].to_numpy()
        follower_vel = self.veh_data.loc[veh_idx, 'vx'].to_numpy()

        if gamma >= gamma_threshold:
            estimated_risk_squared = (
                    ((1 - (1 - rho) ** 2 / gamma) * follower.free_flow_velocity
                     + 2 * follower.lambda1) * follower_vel
                    + follower.lambda1 ** 2
                    - 2 * follower.max_brake * (gap - follower.lambda0)
            )
        else:
            estimated_risk_squared = (
                    (rho ** 2 * follower.free_flow_velocity
                     + 2 * rho * follower.lambda1) * follower_vel
                    + follower.lambda1 ** 2
                    - 2 * follower.max_brake * (1 - gamma)
                    * (gap - follower.lambda0)
            )

        estimated_risk_squared[estimated_risk_squared < 0] = 0
        return np.sqrt(estimated_risk_squared)

    @staticmethod
    def get_braking_parameters_over_time(vehicle_data: pd.DataFrame,
                                         vehicle: Vehicle,
                                         consider_lane_change: bool = True) \
            -> (np.array, np.array, np.array):
        """The vehicle maximum braking is reduced during lane change. This
        function determines when the vehicle is lane changing and returns
        arrays with values of maximum brake and lambda1 at each simulation
        step.

        :param vehicle_data: Must contain either a column 'lane_change' or a
         column 'y'. If only column 'y' exists, sends a warning.
        :param vehicle: object containing the vehicle's parameters
        :param consider_lane_change: if set to false, we don't consider the
         effects of lane change, i.e., we treat all situations as simple
         vehicle following. If set to true, we overestimate the risk by
         assuming a reduced max brake during lane changes.
        :return: Tuple of numpy arrays"""

        # In VISSIM's indication of lane change direction, elements are
        # strings, where 'None' means no lane change.
        # We mimic this by checking the lateral coordinates if the lane
        # change columns is not present.
        if 'lane_change' in vehicle_data.columns:
            lane_change_indicator = vehicle_data['lane_change']
        else:
            warnings.warn('This vehicle record does not contain lane change '
                          'data. It will be estimated by lateral position.\n'
                          'Consider rerunning simulations.')
            lane_change_indicator = (np.abs(
                vehicle_data['y'] - 0.5) < 0.1)
            lane_change_indicator[lane_change_indicator.index[
                lane_change_indicator]] = 'None'

        vehicle_effective_max_brake = (np.ones(len(lane_change_indicator))
                                       * vehicle.max_brake)
        vehicle_effective_lambda1 = (np.ones(len(lane_change_indicator))
                                     * vehicle.lambda1)
        vehicle_effective_tau_j = (np.ones(len(lane_change_indicator))
                                   * vehicle.tau_j)
        if consider_lane_change:
            lane_change_idx = (lane_change_indicator != 'None').to_numpy()
            vehicle_effective_max_brake[lane_change_idx] = (
                vehicle.max_brake_lane_change)
            vehicle_effective_lambda1[lane_change_idx] = (
                vehicle.lambda1_lane_change)
            vehicle_effective_tau_j[lane_change_idx] = (
                vehicle.tau_j_lane_change)

        return (vehicle_effective_max_brake,
                vehicle_effective_lambda1,
                vehicle_effective_tau_j)


class VISSIMDataPostProcessor(ABC):
    """[Probably change name] Class contains a name, a writer and function
    pointer to make creating and saving post-processed data more easy to
    handle"""

    def __init__(self, scenario_name: str,
                 data_name: str, writer):
        """

        :param scenario_name:
        :param data_name:
        """
        self.data_name = data_name
        self.writer = writer(scenario_name)
        self.file_handler = FileHandler(scenario_name)
        # self.post_processing_function = self._mapping[data_name]['function']
        # self.secondary_parameter = secondary_parameter

    @abstractmethod
    def post_process(self, data):
        pass


class SSMProcessor(VISSIMDataPostProcessor):
    _writer = data_writer.SSMDataWriter

    def __init__(self, scenario_name):
        VISSIMDataPostProcessor.__init__(self, scenario_name, 'SSM',
                                         self._writer)
        network_name = self.file_handler.get_network_name()
        if network_name in HIGHWAY_SCENARIOS:
            self.ssm_names = ['low_TTC', 'high_DRAC', 'risk',
                              'risk_no_lane_change']
        elif network_name in TRAFFIC_LIGHT_SCENARIOS:
            self.ssm_names = ['barrier_function_risk']
        else:
            raise ValueError('Unknown network name.')

    def post_process(self, data):
        vehicle_record = data
        if 'leader_type' not in vehicle_record.columns:
            post_process_data(data_source_VISSIM, vehicle_record)
        # Compute
        ssm_estimator = SSMEstimator(vehicle_record)
        ssm_estimator.include_ssms(self.ssm_names)
        # Aggregate
        aggregation_period = 30  # [s]
        new_index = ['time_interval', 'veh_type']
        columns = new_index + self.ssm_names
        create_time_bins_and_labels(aggregation_period, vehicle_record)
        aggregated_ssm = vehicle_record[columns].groupby(
            new_index).sum()
        aggregated_ssm.reset_index(inplace=True)
        aggregated_ssm.insert(0, 'simulation_number', vehicle_record[
            'simulation_number'].iloc[0])
        return aggregated_ssm

    def set_measurements(self, ssm_names: List[str]):
        """
        Define which surrogate safety measurements should be computed by the
        post process function
        :param ssm_names: the names of desired SSMs
        :return:
        """
        self.ssm_names = ssm_names


class RiskyManeuverProcessor(VISSIMDataPostProcessor):
    _writer = data_writer.RiskyManeuverWriter

    def __init__(self, scenario_name):
        VISSIMDataPostProcessor.__init__(self, scenario_name,
                                         'risky_maneuver', self._writer)
        network_name = self.file_handler.get_network_name()
        if network_name in HIGHWAY_SCENARIOS:
            self.risk_name = 'risk'
        elif network_name in TRAFFIC_LIGHT_SCENARIOS:
            self.risk_name = 'barrier_function_risk'
        else:
            raise ValueError('Unknown network name.')

    def post_process(self, data: pd.DataFrame):
        """
        Find risky maneuvers and write their information on a dataframe
        A risky maneuver is defined as a time interval during which risk is
        greater than zero. We save the vehicles involved, start and end
        times, total (sum over duration) risk and pointwise max risk of each
        risky maneuver.

        :param data: dataframe with step by step vehicle data
         including some risk measurement
        :return: dataframe where each row represents one risky maneuver
        """
        vehicle_record = data
        risk_name = self.risk_name
        risk_margin = 0.1  # ignore total risks below this margin

        # Pad the data frame with zero risk entries between vehicles whenever
        # a vehicle starts of ends the simulation with positive risk
        grouped = vehicle_record.groupby('veh_id', as_index=False)
        init_state = grouped.first()
        final_state = grouped.last()
        padding_rows_1 = init_state[init_state['risk'] > 0].copy()
        padding_rows_1['risk'] = 0
        padding_rows_1['time'] -= 0.01
        padding_rows_2 = final_state[final_state['risk'] > 0].copy()
        padding_rows_2['risk'] = 0
        padding_rows_2['time'] += 0.01
        padded_vehicle_records = (pd.concat([vehicle_record, padding_rows_1,
                                             padding_rows_2]).
                                  sort_values(['veh_id', 'time', 'risk']).
                                  reset_index(drop=True))

        # Now we can look for "groups" of positive risk
        delta_t = round(padded_vehicle_records['time'].iloc[0:2].diff()[1], 2)
        padded_vehicle_records['is_risk_positive'] = (
                padded_vehicle_records[risk_name] > 0)
        risk_transition_idx = padded_vehicle_records[
            padded_vehicle_records['is_risk_positive'].diff().fillna(False)
            != 0]
        # To do a cumulative sum that resets every time there's a zero
        # mask = padded_vehicle_records['risk'] != 0
        # total_risk = (mask.cumsum()
        #               - mask.cumsum().where(~mask).ffill().fillna(0).
        #               astype(int)) * delta_t
        risk = padded_vehicle_records['risk']
        risk_grouped = risk.groupby((risk == 0).cumsum())
        cumulative_risk = risk_grouped.cumsum() * delta_t
        cumulative_max_risk = risk_grouped.cummax()
        start_indices = risk_transition_idx.iloc[::2].index
        end_indices = risk_transition_idx.iloc[1::2].index

        # And finally create the data frame which contains one risky maneuver
        # per row
        risky_data = padded_vehicle_records[
            ['veh_id', 'veh_type', 'leader_id', 'time']].loc[start_indices]
        risky_data['end_time'] = padded_vehicle_records['time'].loc[
            end_indices].to_numpy()
        risky_data['total_risk'] = cumulative_risk.shift().loc[
            end_indices].to_numpy()
        risky_data['max_risk'] = cumulative_max_risk.shift().loc[
            end_indices].to_numpy()
        risky_data.drop(
            index=risky_data[risky_data['total_risk'] < risk_margin].index,
            inplace=True)

        if risky_data.empty:
            risky_data.loc[0] = 0
        risky_data['simulation_number'] = vehicle_record[
            'simulation_number'].iloc[0]
        return risky_data

    def set_risk(self, risk_name: str):
        """
        Define which measurement of risk is used to extract risky intervals
        :param risk_name: the name of the risk measurement
        :return:
        """
        self.risk_name = risk_name


class ViolationProcessor(VISSIMDataPostProcessor):
    _writer = data_writer.TrafficLightViolationWriter

    def __init__(self, scenario_name):
        VISSIMDataPostProcessor.__init__(self, scenario_name,
                                         'violation', self._writer)
        traffic_light_reader = readers.TrafficLightSourceReader(
            scenario_name)
        self.traffic_light_data = traffic_light_reader.load_data()
        self._compute_cycle_times()

    def post_process(self, data):
        """
        Finds red light running violations in a single simulation.

        :param data: dataframe with step by step vehicle data
        :return: dataframe where each row represents one traffic light violation
        """
        vehicle_record = data
        violations_list = []
        warmup_time = vehicle_record['time'].iloc[0]
        for _, tf in self.traffic_light_data.iterrows():
            vehicle_record['dist_to_tf'] = (vehicle_record['x']
                                            - tf['position'])
            after_tf = vehicle_record[vehicle_record['dist_to_tf'] > 0]
            crossing_time = after_tf.loc[
                after_tf.groupby('veh_id').dist_to_tf.idxmin(), 'time']
            crossing_time = crossing_time[crossing_time > warmup_time]
            tf_cycle = tf['cycle_time']
            violation_idx = crossing_time[(crossing_time % tf_cycle) <
                                          tf['red duration']].index
            violations_per_tf = vehicle_record.loc[
                violation_idx, ['simulation_number', 'veh_id', 'veh_type',
                                'time',
                                'vehicles_per_lane']]
            violations_per_tf['traffic_light'] = tf['id']
            violations_list.append(violations_per_tf)
        return pd.concat(violations_list)

    def _compute_cycle_times(self):
        if 'starts_red' not in self.traffic_light_data.columns:
            self.traffic_light_data['starts_red'] = True
        self.traffic_light_data['cycle_time'] = (
                self.traffic_light_data['red duration']
                + self.traffic_light_data['green duration']
                + self.traffic_light_data['amber duration'])


class DiscomfortProcessor(VISSIMDataPostProcessor):
    _writer = data_writer.DiscomfortWriter

    def __init__(self, scenario_name):
        VISSIMDataPostProcessor.__init__(self, scenario_name,
                                         'discomfort', self._writer)
        self.comfortable_brake = [-i for i in range(3, 10)]

    def post_process(self, data):
        """
        Computes discomfort as the integral of
        |a(t) - a_comf| if |a(t)| > a_comf.

        :param data: vehicle records data loaded from VISSIM
        :return: Dataframe with values of discomfort for all vehicles every
        'aggregation period' seconds
        """
        vehicle_records = data
        sampling_interval = (vehicle_records['time'].iloc[1]
                             - vehicle_records['time'].iloc[0])
        discomfort_columns = []
        for b in self.comfortable_brake:
            discomfort_idx = vehicle_records['ax'] < b
            col_name = 'discomfort_' + str(-b)
            vehicle_records[col_name] = 0
            vehicle_records.loc[discomfort_idx, col_name] = (
                    b - vehicle_records.loc[discomfort_idx, 'ax']
            )
            discomfort_columns.append(col_name)

        try:
            aggregated_acceleration = vehicle_records.groupby(
                ['veh_type', 'time_interval'])[discomfort_columns].sum()
        except KeyError:
            aggregation_period = 30
            create_time_bins_and_labels(aggregation_period, vehicle_records)
            aggregated_acceleration = vehicle_records.groupby(
                ['veh_type', 'time_interval'])[discomfort_columns].sum()
        aggregated_acceleration *= sampling_interval
        aggregated_acceleration.reset_index(inplace=True)
        aggregated_acceleration.insert(
            0, 'simulation_number',
            vehicle_records['simulation_number'].iloc[0])
        return aggregated_acceleration


class LaneChangeIssuesProcessor(VISSIMDataPostProcessor):
    _writer = data_writer.LaneChangeIssuesWriter

    def __init__(self, scenario_name):
        VISSIMDataPostProcessor.__init__(self, scenario_name,
                                         'lane_change_issues', self._writer)
        self.exit_links = [5, 6]  # exit links for the in_and_out scenario

    def post_process(self, data):
        """
        :param data: Vehicle record of a VISSIM simulation
        """
        # Find removed vehicles
        max_time = data.iloc[-1]['time']
        last_entry_per_veh = data.groupby('veh_id', as_index=False).last()
        removed_vehicles = last_entry_per_veh.loc[
            ~(last_entry_per_veh['link'].isin(self.exit_links))
            & (last_entry_per_veh['time'] < max_time), ['time', 'veh_id']]
        removed_vehicles['issue'] = 'removed'

        # Find AVs which needed human intervention
        blocked_samples = data.loc[
            (data['vissim_control'] == 1)
            & (data['veh_type'] != Vehicle.VISSIM_CAR_ID),
            ['time', 'veh_id']]
        blocked_vehicles = blocked_samples.groupby('veh_id',
                                                   as_index=False).first()
        blocked_vehicles['issue'] = 'blocked AV'

        issues_df = pd.concat([removed_vehicles, blocked_vehicles])
        issues_df['simulation_number'] = data['simulation_number'].iloc[0]
        return issues_df
