import numpy as np
import os
import pandas as pd
from scipy.stats import truncnorm
import readers


class DataAnalyzer:

    def __init__(self, data_source, sim_name, raw=False):
        """
        Starts a readers.DataReader object to be used later by the methods
        :param data_source: string 'vissim' or 'ngsim'
        :param sim_name:
        :param raw: determines whether we read the original or post-processed files
        """
        if data_source.lower == 'vissim':
            self.reader = readers.VissimDataReader(sim_name)
        elif data_source.lower() == 'ngsim':
            self.reader = readers.NGSIMDataReader(sim_name)
        else:
            print('{}: Unknown data source'.format(type(self)))
            self.reader = readers.DataReader(None, None)
        if not raw:
            print('Loading post processed CSV file')
            self.veh_records = self.reader.load_from_csv()
        if raw or len(self.veh_records) == 0:
            print('Loading raw data')
            self.veh_records = self.reader.load_data()
        self.max_decel_df = None

    def post_process_vissim_data(self):
        """
        Process fzp vehicle record data file generated by VISSIM
        :return: None
        """

        # Only use samples after some vehicles have already left the simulation
        n_discarded = 10  # number of vehicles

        df = self.veh_records

        # Define warm up time as moment when first 10 vehicles have left simulation
        warm_up_time = max(df.loc[df['veh_id'] <= n_discarded, 'time'])

        # Compute relative velocity to the vehicle's leader (own vel minus leader vel) Note: we need this
        # function because VISSIM's output 'SpeedDiff' is not always correct. It has been observed to equal the
        # vehicle's own speed at the previous time step.
        self.compute_delta_v(warm_up_time)
        # if 'delta_v' in df.columns:
        #     print('Dataframe {} already has delta v'.format(self.reader.file_name))
        #     return
        # print('Computing delta v for file: {}'.format(self.reader.file_name))
        # df.set_index('time', inplace=True)
        # df.drop(index=[i for i in df.loc[df.index <= warm_up_time].index], inplace=True)
        # df['leader_id'].fillna(df['veh_id'], inplace=True, downcast='infer')
        # n_veh = max(df['veh_id'])
        # identity = np.eye(n_veh)
        #
        # sim_times = np.unique(df.index)
        # percent = 0.1
        # for i in range(len(sim_times)):
        #     t = sim_times[i]
        #     adj_matrix = np.zeros([n_veh, n_veh])
        #     vel_vector = np.zeros(n_veh)
        #     this_time = df.loc[t, 'veh_id']
        #
        #     veh_idx = [i - 1 for i in this_time]
        #     adj_matrix[veh_idx, df.loc[t, 'leader_id'].values - 1] = -1
        #     vel_vector[veh_idx] = df.loc[t, 'vx']
        #     df.loc[t, 'delta_v'] = np.matmul((identity + adj_matrix), vel_vector)[veh_idx]
        #     if i == int(percent * len(sim_times)):
        #         print('{}% done'.format(int(i / len(sim_times) * 100)))
        #         percent += 0.1
        #
        # df.reset_index(inplace=True)

    def post_process_ngsim_data(self):
        """
        Process csv data file generated from NGSIM
        :return: None
        """
        base_time = min(self.veh_records['Global_Time'])
        self.veh_records['Global_Time'] = (self.veh_records['Global_Time'] - base_time)//100

        # Define warm up time as the first moment some vehicle has a leader
        warm_up_time = min(self.veh_records.loc[self.veh_records['Preceding'] > 0, 'Global_Time'])
        self.compute_delta_v(warm_up_time, time_str='Global_Time', veh_id_str='Vehicle_ID',
                             vel_str='v_Vel', leader_id_str='Preceding')

    def compute_delta_v(self, warm_up_time, time_str='time', veh_id_str='veh_id',
                        vel_str='vx', leader_id_str='leader_id'):

        df = self.veh_records
        if 'delta_v' in df:
            print('Dataframe {} already has delta v'.format(self.reader.file_name))
            return

        print('Computing delta v for file: {}'.format(self.reader.file_name))
        df.set_index(time_str, inplace=True)
        df.drop(index=[i for i in df.loc[df.index <= warm_up_time].index], inplace=True)
        df[leader_id_str].fillna(df[veh_id_str], inplace=True, downcast='infer')
        n_veh = max(df[veh_id_str])
        identity = np.eye(n_veh)

        sim_times = np.unique(df.index)
        percent = 0.1
        for i in range(len(sim_times)):
            t = sim_times[i]
            adj_matrix = np.zeros([n_veh, n_veh])
            vel_vector = np.zeros(n_veh)
            this_time = df.loc[t, veh_id_str]

            veh_idx = [i - 1 for i in this_time]
            adj_matrix[veh_idx, df.loc[t, leader_id_str].values - 1] = -1
            vel_vector[veh_idx] = df.loc[t, vel_str]
            df.loc[t, 'delta_v'] = np.matmul((identity + adj_matrix), vel_vector)[veh_idx]
            if i == int(percent * len(sim_times)):
                print('{}% done'.format(int(i / len(sim_times) * 100)))
                percent += 0.1

        df.reset_index(inplace=True)

    def save_to_csv(self, data_dir):
        self.veh_records.to_csv(os.path.join(data_dir, self.reader.file_name + '.csv'), index=False)

    # TODO: check the computations below for a couple of vehicles and ensure they're properly coded
    def include_ttc(self):
        """
        Includes Time To Collision (TTC) as a column in dataframes in the dictionary
        :return: None
        """
        # TTC = deltaX/deltaV if follower is faster; otherwise infinity
        df = self.veh_records
        if 'delta_v' not in df.columns:
            self.post_process_vissim_data()
        df['TTC'] = float('inf')
        valid_ttc_idx = df['delta_v'] > 0
        df.loc[valid_ttc_idx, 'TTC'] = df.loc[valid_ttc_idx, 'delta_x'] / df.loc[valid_ttc_idx, 'delta_v']
        # df.loc[df['delta_v'] <= 0, 'TTC'] = float('inf')

    def include_drac(self):
        """
        Includes Deceleration Rate to Avoid Collision (DRAC) as a column in dataframes in the dictionary
        :return: None
        """
        # DRAC = deltaV^2/(2.deltaX), if follower is faster; otherwise zero

        df = self.veh_records
        if 'delta_v' not in df.columns:
            self.post_process_vissim_data()
        df['DRAC'] = 0
        valid_drac_idx = df['delta_v'] > 0
        df.loc[valid_drac_idx, 'DRAC'] = df.loc[valid_drac_idx, 'delta_v'] ** 2 / 2 / df.loc[valid_drac_idx, 'delta_x']
        # df.loc[df['delta_v'] < 0, 'DRAC'] = 0
        # drac_mean = df.loc[df['DRAC'] > 0, 'DRAC'].mean()

    def include_cpi(self, default_vissim=True):
        """
        Includes Crash Probability Index (CPI) as a column in dataframes in the dictionary
        :param default_vissim: boolean to identify if data was generated using default VISSIM deceleration parameters
        :return: None
        """
        # CPI = Prob(DRAC > MADR), where MADR is the maximum available deceleration rate
        # Formally, we should check the truncated Gaussian parameters for each velocity. However, the default VISSIM
        # max decel is a linear function of the velocity and the other three parameters are constant. We make use of
        # this to speed up this function.

        if self.max_decel_df is None:
            self.max_decel_df = self.reader.load_max_decel_data()

        veh_type_array = np.unique(self.max_decel_df.index.get_level_values('veh_type'))
        df = self.veh_records
        if 'DRAC' not in df.columns:
            self.include_drac()
        df['CPI'] = 0
        # veh_type_array = np.unique(df['veh type'])
        for veh_type in veh_type_array:
            idx = (df['veh type'] == veh_type) & (df['DRAC'] > 0)
            if not default_vissim:
                a_array = []
                b_array = []
                madr_array = []
                std_array = []
                for vel in df.loc[idx, 'vx']:
                    row = self.max_decel_df.loc[veh_type, round(vel, -1)]
                    a_array.append(row['norm_min'])
                    b_array.append(row['norm_max'])
                    madr_array.append(-1 * row['mean'])
                    std_array.append(row['std'])
                df.loc[idx, 'CPI'] = truncnorm.cdf(df.loc[idx, 'DRAC'], a=a_array, b=b_array,
                                                   loc=madr_array, scale=std_array)
            else:
                first_row = self.max_decel_df.loc[veh_type, 0]
                possible_vel = self.max_decel_df.loc[veh_type].index
                min_vel = 0
                max_vel = max(possible_vel)
                decel_min_vel = self.max_decel_df.loc[veh_type, min_vel]['mean']
                decel_max_vel = self.max_decel_df.loc[veh_type, max_vel]['mean']
                madr_array = decel_min_vel + (decel_max_vel - decel_min_vel) / max_vel * df.loc[idx, 'vx']
                df.loc[idx, 'CPI'] = truncnorm.cdf(df.loc[idx, 'DRAC'], a=first_row['norm_min'],
                                                   b=first_row['norm_max'], loc=(-1) * madr_array,
                                                   scale=first_row['std'])

    def include_safe_gaps(self, rho=0.2, free_flow_vel=30):
        """
        Includes safe gap and time headway-based gap as columns in dataframes in the dictionary
        :param rho: expected maximum relative velocity, defined as vE - vL <= rho.vE
        :param free_flow_vel: should be given in m/s
        :return: None
        """
        # Safe gap is the worst-case collision-free gap (as close as possible to minimum gap to avoid collision under
        # emergency braking)
        # Time headway-based gap (th gap) is the linear overestimation of the safe gap

        # TODO: braking parameters set based on typical values. Consider extracting from VISSIM
        # TODO: get leader max brake from its type
        # TODO: consider case where (ego max brake) > (leader max brake)

        if self.max_decel_df is None:
            self.max_decel_df = self.reader.load_max_decel_data()

        # Veh types:
        veh_type_array = np.unique(self.max_decel_df.index.get_level_values('veh_type'))

        # Parameters
        mps_to_kph = 3.6
        accel_t0 = 0.5
        max_brake = {100: 6.5, 200: 5.5}
        max_jerk = {100: 50, 200: 30}
        tau_d = 0.2
        veh_params = pd.DataFrame(columns=['max_brake', 'lambda0', 'lambda1'])
        for key in max_brake.keys():
            tau_j = (accel_t0 + max_brake[key]) / max_jerk[key]
            lambda1 = (accel_t0 + max_brake[key]) * (tau_d + tau_j / 2)
            lambda0 = -(accel_t0 + max_brake[key]) / 2 * (tau_d ** 2 + tau_d * tau_j + tau_j ** 2 / 3)
            veh_params.loc[key] = [max_brake[key], lambda0, lambda1]

        df = self.veh_records
        df['safe gap'] = 0
        change_idx = df['number'] != df['leader number']
        ego_vel = df['vx'] / mps_to_kph
        leader_vel = ego_vel - df['delta_v'] / mps_to_kph
        for veh_type in veh_type_array:
            max_brake_ego, lambda0, lambda1 = veh_params.loc[veh_type]
            gamma = 1  # max_brake_ego/max_brake_leader
            time_headway = ((1 / 2 - (1 - rho) ** 2 / 2 / gamma) * free_flow_vel + lambda1) / max_brake_ego
            standstill_gap = lambda1 ** 2 / 2 / max_brake_ego + lambda0
            veh_type_idx = df['veh type'] == veh_type
            df.loc[veh_type_idx & change_idx, 'safe gap'] = \
                ego_vel ** 2 / 2 / max_brake_ego - leader_vel ** 2 / 2 / max_brake_ego \
                + lambda1 * ego_vel / max_brake_ego + lambda1 ** 2 / 2 / max_brake_ego + lambda0
            df[df['safe gap'] < 0] = 0
            df['DTSG'] = df['delta_x'] - df['safe gap']
            df.loc[(df['veh type'] == veh_type) & change_idx, 'time headway gap'] = \
                time_headway * ego_vel + standstill_gap
