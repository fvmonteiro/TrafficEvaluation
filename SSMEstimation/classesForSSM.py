import numpy as np
import os
import pandas as pd
from scipy.stats import truncnorm
import readers


class DataAnalyzer:

    def __init__(self, data_source, data):
        """
        :param data_source: string 'vissim' or 'ngsim'
        :param data: pandas dataframe with vehicle trajectory data
        """
        self.data_source = data_source
        self.veh_records = data

    def post_process_data(self):
        if self.data_source.lower() == 'vissim':
            self.post_process_vissim_data()
        elif self.data_source.lower() == 'ngsim':
            self.post_process_ngsim_data()
        else:
            print('[{}] Trying to process data from unknown data source'.format(type(self)))
            return

    def post_process_vissim_data(self):
        """
        Process fzp vehicle record data file generated by VISSIM
        :return: None
        """
        # Only use samples after some vehicles have already left the simulation
        n_discarded = 10  # number of vehicles

        # Define warm up time as moment when first 10 vehicles have left simulation
        warm_up_time = max(self.veh_records.loc[self.veh_records['veh_id'] <= n_discarded, 'time'])

        # By convention, if vehicle has no leader, we set it as its own leader
        self.veh_records['leader_id'].fillna(self.veh_records['veh_id'], inplace=True, downcast='infer')

        # Compute relative velocity to the vehicle's leader (own vel minus leader vel) Note: we need this
        # function because VISSIM's output 'SpeedDiff' is not always correct. It has been observed to equal the
        # vehicle's own speed at the previous time step.
        self.compute_delta_v(warm_up_time)

    def post_process_ngsim_data(self):
        """
        Process csv data file generated from NGSIM
        :return: None
        """
        # Time from NGSIM is in milliseconds
        base_time = min(self.veh_records['time'])
        self.veh_records['time'] = (self.veh_records['time'] - base_time)//100

        foot_to_meter = 0.3048
        self.veh_records['vx'] = self.veh_records['vx']*foot_to_meter

        desired_data_types = {'veh_id': int, 'leader_id': int, 'veh_type': int}
        self.veh_records = self.veh_records.astype(desired_data_types)

        # By convention, if vehicle has no leader, we set it as its own leader
        self.veh_records.loc[self.veh_records['leader_id'] == 0, 'leader_id'] = self.veh_records['veh_id']

        # Define warm up time as the first moment some vehicle has a leader
        warm_up_time = min(self.veh_records.loc[self.veh_records['leader_id'] > 0, 'time'])
        self.compute_delta_v(warm_up_time)

    def compute_delta_v(self, warm_up_time):

        df = self.veh_records
        if 'delta_v' in df:
            print('Dataframe already has delta v')
            return

        print('Computing delta v...')
        df.set_index('time', inplace=True)
        df.drop(index=[i for i in df.loc[df.index <= warm_up_time].index], inplace=True)

        # By convention, if vehicle has no leader, we set it as its own leader
        # df['leader_id'].fillna(df['veh_id'], inplace=True, downcast='infer')

        max_size = max(df['veh_id']) + 1  # +1 to compensate zero indexing
        identity = np.eye(max_size)

        sim_times = np.unique(df.index)
        percent = 0.1
        out_of_bounds_counter = 0
        for i in range(len(sim_times)):
            current_time = sim_times[i]
            current_data = df.loc[[current_time]]
            adj_matrix = np.zeros([max_size, max_size])
            vel_vector = np.zeros(max_size)

            veh_idx = current_data['veh_id'].values
            leader_idx = current_data['leader_id'].values
            # If leader is not in the current time, we proceed as if there was no leader.
            out_of_bounds = leader_idx >= max_size
            out_of_bounds_counter += sum(out_of_bounds)
            leader_idx[out_of_bounds] = veh_idx[out_of_bounds]
            adj_matrix[veh_idx, leader_idx] = -1

            vel_vector[veh_idx] = current_data['vx']
            delta_v = np.matmul((identity + adj_matrix), vel_vector)[veh_idx]

            df.loc[current_time, 'delta_v'] = delta_v

            if i == int(percent * len(sim_times)):
                print('{}% done'.format(int(i / len(sim_times) * 100)))
                percent += 0.1

        print('Out of bounds leaders found in {} out of {} samples ({}%)'.
              format(out_of_bounds_counter, df.shape[0], int(out_of_bounds_counter/df.shape[0] * 100)))

        df.reset_index(inplace=True)

    def save_to_csv(self, file_name):
        """
        Save only necessary columns to csv
        :param file_name: string with file name (no .csv needed)
        :return:
        """
        processed_data_dir = os.path.join('C:\\Users\\fvall\\Documents\\Research'
                                          '\\TrafficSimulation\\post_processed_data', self.data_source.upper())
        self.veh_records.to_csv(os.path.join(processed_data_dir, file_name + '.csv'), index=False)

    def include_ttc(self):
        """
        Includes Time To Collision (TTC) as a column in dataframes in the dictionary
        :return: None
        """
        # TTC = deltaX/deltaV if follower is faster; otherwise infinity
        df = self.veh_records
        if 'delta_v' not in df.columns:
            self.post_process_vissim_data()
        df['TTC'] = float('inf')
        valid_ttc_idx = df['delta_v'] > 0
        df.loc[valid_ttc_idx, 'TTC'] = df.loc[valid_ttc_idx, 'delta_x'] / df.loc[valid_ttc_idx, 'delta_v']
        # df.loc[df['delta_v'] <= 0, 'TTC'] = float('inf')

    def include_drac(self):
        """
        Includes Deceleration Rate to Avoid Collision (DRAC) as a column in dataframes in the dictionary
        :return: None
        """
        # DRAC = deltaV^2/(2.deltaX), if follower is faster; otherwise zero

        df = self.veh_records
        if 'delta_v' not in df.columns:
            self.post_process_vissim_data()
        df['DRAC'] = 0
        valid_drac_idx = df['delta_v'] > 0
        df.loc[valid_drac_idx, 'DRAC'] = df.loc[valid_drac_idx, 'delta_v'] ** 2 / 2 / df.loc[valid_drac_idx, 'delta_x']
        # df.loc[df['delta_v'] < 0, 'DRAC'] = 0
        # drac_mean = df.loc[df['DRAC'] > 0, 'DRAC'].mean()

    def include_cpi(self, max_decel_data, is_default_vissim=True):
        """
        Includes Crash Probability Index (CPI) as a column in dataframes in the dictionary
        :param max_decel_data: dataframe with maximum deceleration per vehicle type
        :param is_default_vissim: boolean to identify if data was generated using default VISSIM deceleration parameters
        :return: None
        """
        # CPI = Prob(DRAC > MADR), where MADR is the maximum available deceleration rate
        # Formally, we should check the truncated Gaussian parameters for each velocity. However, the default VISSIM
        # max decel is a linear function of the velocity and the other three parameters are constant. We make use of
        # this to speed up this function.

        # if self.max_decel_df is None:
        #     self.max_decel_df = self.reader.load_max_decel_data()

        veh_type_array = np.unique(max_decel_data.index.get_level_values('veh_type'))
        df = self.veh_records
        if 'DRAC' not in df.columns:
            self.include_drac()
        df['CPI'] = 0
        # veh_type_array = np.unique(df['veh type'])
        for veh_type in veh_type_array:
            idx = (df['veh type'] == veh_type) & (df['DRAC'] > 0)
            if not is_default_vissim:
                a_array = []
                b_array = []
                madr_array = []
                std_array = []
                for vel in df.loc[idx, 'vx']:
                    row = max_decel_data.loc[veh_type, round(vel, -1)]
                    a_array.append(row['norm_min'])
                    b_array.append(row['norm_max'])
                    madr_array.append(-1 * row['mean'])
                    std_array.append(row['std'])
                df.loc[idx, 'CPI'] = truncnorm.cdf(df.loc[idx, 'DRAC'], a=a_array, b=b_array,
                                                   loc=madr_array, scale=std_array)
            else:
                first_row = max_decel_data.loc[veh_type, 0]
                possible_vel = max_decel_data.loc[veh_type].index
                min_vel = 0
                max_vel = max(possible_vel)
                decel_min_vel = max_decel_data.loc[veh_type, min_vel]['mean']
                decel_max_vel = max_decel_data.loc[veh_type, max_vel]['mean']
                madr_array = decel_min_vel + (decel_max_vel - decel_min_vel) / max_vel * df.loc[idx, 'vx']
                df.loc[idx, 'CPI'] = truncnorm.cdf(df.loc[idx, 'DRAC'], a=first_row['norm_min'],
                                                   b=first_row['norm_max'], loc=(-1) * madr_array,
                                                   scale=first_row['std'])

    def include_safe_gaps(self, rho=0.2, free_flow_vel=30):
        """
        Includes safe gap and time headway-based gap as columns in dataframes in the dictionary
        :param rho: expected maximum relative velocity, defined as vE - vL <= rho.vE
        :param free_flow_vel: should be given in m/s
        :return: None
        """
        # Safe gap is the worst-case collision-free gap (as close as possible to minimum gap to avoid collision under
        # emergency braking)
        # Time headway-based gap (th gap) is the linear overestimation of the safe gap

        # TODO: braking parameters set based on typical values. Consider extracting from VISSIM
        # TODO: get leader max brake from its type
        # TODO: consider case where (ego max brake) > (leader max brake)
        # TODO: adapt to NGSIM

        # Veh types:
        veh_type_array = np.unique(self.veh_records('veh_type'))

        # Parameters
        mps_to_kph = 3.6
        accel_t0 = 0.5
        max_brake = {100: 6.5, 200: 5.5}
        max_jerk = {100: 50, 200: 30}
        tau_d = 0.2
        veh_params = pd.DataFrame(columns=['max_brake', 'lambda0', 'lambda1'])
        for key in max_brake.keys():
            tau_j = (accel_t0 + max_brake[key]) / max_jerk[key]
            lambda1 = (accel_t0 + max_brake[key]) * (tau_d + tau_j / 2)
            lambda0 = -(accel_t0 + max_brake[key]) / 2 * (tau_d ** 2 + tau_d * tau_j + tau_j ** 2 / 3)
            veh_params.loc[key] = [max_brake[key], lambda0, lambda1]

        df = self.veh_records
        df['safe_gap'] = 0
        change_idx = df['veh_id'] != df['leader_id']
        ego_vel = df['vx'] / mps_to_kph
        leader_vel = ego_vel - df['delta_v'] / mps_to_kph
        for veh_type in veh_type_array:
            max_brake_ego, lambda0, lambda1 = veh_params.loc[veh_type]
            gamma = 1  # max_brake_ego/max_brake_leader
            time_headway = ((1 / 2 - (1 - rho) ** 2 / 2 / gamma) * free_flow_vel + lambda1) / max_brake_ego
            standstill_gap = lambda1 ** 2 / 2 / max_brake_ego + lambda0
            veh_type_idx = df['veh_type'] == veh_type
            df.loc[veh_type_idx & change_idx, 'safe_gap'] = \
                ego_vel ** 2 / 2 / max_brake_ego - leader_vel ** 2 / 2 / max_brake_ego \
                + lambda1 * ego_vel / max_brake_ego + lambda1 ** 2 / 2 / max_brake_ego + lambda0
            df[df['safe_gap'] < 0] = 0
            df['DTSG'] = df['delta_x'] - df['safe_gap']
            df.loc[(df['veh_type'] == veh_type) & change_idx, 'time_headway_gap'] = \
                time_headway * ego_vel + standstill_gap
